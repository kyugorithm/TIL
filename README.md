# TIL
- 기록은 모든것의 기본이다. 보고 배운것과 해본것들을 꾸준히 남기도록 한다.
# Principles
- 양이 적더라도 매일 업데이트 하려고 노력하자. 꾸준함이 중요하다.  
- 다시 보았을 때 불편함이 없도록 명료하게 작성한다.
- 이론본다고 코드공부도 게을리하지 않기~!




# 정리필요 목록 : Last updated 2022/01/11
```
(2021) StyTr^2: Unbiased Image Style Transfer with Transformers  
(2021) GPEN : GAN Prior Embedded Network for Blind Face Restoration in the Wild
(2020) NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis  
  
(2020) Neural Head Reenactment with Latent Pose Descriptors
(2020) First Order Model for Image Animation
(2020) One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing 
(2020) DataAugmentation : Fair Attribute Classification through Latent Space De-biasing
  
Face swap/reenactment
(2018) RSGAN: Face Swapping and Editing using Face and Hair Representation in Latent Spaces
(2018) ReenactGAN: Learning to Reenact Faces via Boundary Transfer
(2016) Face2Face: Real-time Face Capture and Reenactment of RGB Videos

(2016) Loss Functions for Image Restoration with Neural Networks ; L1 vs L2 vs SSIM family
```

## Neural Rendering
```
(2020) State of the Art on Neural Rendering
```
## 3DMM
```
(2020) StyleRig : Rigging StyleGAN for 3D Control over Portrait Images
(1999) A Morphable Model For The Synthesis Of 3D Faces
```

## Anomaly Detection
```
(2019) OCGAN: One-class Novelty Detection Using GANs with Constrained Latent
(2018) DeepAnT: A Deep Learning Approach for Unsupervised Anomaly Detection in Time Series
(2018) GANomaly : Semi-Supervised Anomaly Detection via Adversarial Training
(2017) AnoGAN : Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery  
```
## Battery
```
(2019) Data-driven health estimation and lifetime prediction of lithium-ion batteries: A review
```
## CAM
```
(2020) Don't Judge an Object by Its Context: Learning to Overcome Contextual Bias
(2016) Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization
(2015) CAM : Learning Deep Features for Discriminative Localization
```
## Classification
```
(2020) How Much Position Information Do Convolutional Neural Networks Encode?
(2018) ArcFace: Additive Angular Margin Loss for Deep Face Recognition
```
## Colorization
```
(2017) RTUG : Real-Time User-Guided Image Colorization with Learned Deep Priors
```
## Data Augmentation
```
(2021) StyleMix : Separating Content and Style for Enhanced Data Augmentation
```
## FaceSwap
```
(2021) HifiFace: 3D Shape and Semantic Prior Guided High Fidelity Face Swapping
(2021) SimSwap: An Efficient Framework For High Fidelity Face Swapping
(2020) DeepFaceLab: Integrated, flexible and extensible face-swapping framework
(2019) FaceShifter: Towards High Fidelity And Occlusion Aware Face Swapping
(2019) FSGAN: Subject Agnostic Face Swapping and Reenactment

(2017) On Face Segmentation, Face Swapping, and Face Perception
```
## Generative Model
```
(2014) Generative Adversarial Networks  
```
## I2I translation
```
(2021) Not just Compete, but Collaborate: Local Image-to-Image Translation via Cooperative Mask Prediction
(2020) AttentionGAN: Unpaired Image-to-Image Translation using Attention-Guided Generative Adversarial Networks
(2020) GANHopper : Multi-Hop GAN for Unsupervised Image-to-Image Translation
(2019) U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for I2I Translation
(2019) StarGAN v2: Diverse Image Synthesis for Multiple Domains
(2019) AMGAN : Attribute Manipulation Generative Adversarial Networks for Fashion Images
(2018) StarGAN : Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation
(2018) Ganimorph : Improving Shape Deformation in Unsupervised I2I Translation
(2017) CycleGAN : Unpaired Image-to-Image Translation using Cycle-Consistent
```
## Image Synthesis
```
(2021) StyleGAN v3 : Alias-Free Generative Adversarial Networks
(2021) StyleMapGAN : Exploiting Spatial Dimensions of Latent in GAN for Real-time Image Editing : TBD
(2020) A U-Net Based Discriminator for Generative Adversarial Networks
(2020) StyleGAN v2 : Analyzing and Improving the Image Quality of StyleGAN
(2019) StyleGAN v1 : A Style-Based Generator Architecture for Generative Adversarial Networks
(2019) MSGAN : Mode Seeking Generative Adversarial Networks for Diverse Image Synthesis
(2019) MSG-GAN: Multi-Scale Gradients for Generative Adversarial Networks 
(2018) PGGAN : Progressive Growing of GANs for Improved Quality, Stability, and Variation
(2016) Improved Techniques for Training GANs : **TBD**
```
## LypSync
```
(2017) Audio-Driven Facial Animation by Joint End-to-End Learning of Pose and Emotion : TBD
```
## Normalization
```
(2016) Layer Normalization
```
## 3D Human Pose Estimation
```
(2022) MixSTE: Seq2seq Mixed Spatio-Temporal Encoder for 3D Human Pose Estimation in Video
(2021) Improving Robustness and Accuracy via Relative Information Encoding in 3D Human Pose Estimation
(2021) MoVNect : Lightweight 3D Human Pose Estimation Network Training Using Teacher-Student Learning
(2017) VNect: Real-time 3D Human Pose Estimation with a Single RGB Camera
(2006) Recovering 3D Human Pose from Monocular Images

```
## Self Attention
```
(2018) CBAM: Convolutional Block Attention Module
(2018) BAM: Bottleneck Attention Module” , in BMVC 2018
```
## Syle Transfer
```
(2021) StyTr^2: Unbiased Image Style Transfer with Transformers
(2017) Arbitrary Style Transfer in Real-time with Adaptive Instance
(2016) Image Style Transfer Using Convolutional Neural Networks
(2001) Image Analogies
```
## Time Series
```
(2019) TimeGAN : Time-series Generative Adversarial Networks
(2017) RCGAN : REAL-VALUED (MEDICAL) TIME SERIES GENERATION WITH RECURRENT CONDITIONAL GANS
```
## WSSS
```
(2020) Unsupervised Learning of Image Segmentation Based on Differentiable Feature Clustering
```

## Attention
```
(2019) Stand-Alone Self-Attention in Vision Models
```


## Object Detection
```
(2021) Dynamic Head: Unifying Object Detection Heads with Attentions
```

## Dataset
```
(2017) VGGFace2: A dataset for recognising faces across pose and age
```

## Animation
```
(2020) First Order Motion Model for Image Animation
```

## Novel View Synthesis
```
(2020) NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis
```





# 2. 그외 이론및 모델

[Graphical Model?][b_link001] : 상태를 가지는 모델에서 directed/indirected graphical model의 개념이 자주 등장한다.  
[Restricted Boltzmann Machine][b_link002] : 깊은 신경망에서 학습이 잘 되지 않는 문제를 해결하기 위해 Geoffrey Hinton 교수님이 제안하신 방법론  
Gradient vanishing을 사전학습으로 풀어낸다. 이를 통해 DL이 다시 활기를 되찾았다. Generative 계열을 이해하기 위해서는 이해 필수
[MCMC(Monte Carlo Markov Chain)][b_link003] : 샘플링 방법론
[Pytorch Manual][b_link004] : 파이토치 사용매뉴얼
 # Text book 
 [Machine Learning : A Probabilistic Perspective][t_link001] : ML의 바이블이라고 생각하는 책이다. 언젠간 보고 정리해야겠다고 생각했는데, 언제 다볼 수 있을지... 

# 3. Coursera
<p>
 <img src="https://user-images.githubusercontent.com/40943064/147326092-656e97b0-c871-4a7a-a54d-caab6241c2a7.png" width=350 />
 <img src="https://user-images.githubusercontent.com/40943064/147326779-0ef9aa86-9573-4d5c-b8cc-12353b5ed655.png" width=352 />
</p>


[j_link001]: <https://arxiv.org/pdf/1508.06576.pd>
[j_link002]: <https://ieeexplore.ieee.org/document/8581424>
[j_link003]: <https://ieeexplore.ieee.org/document/9171158>
[j_link004]: <https://www.technicaljournalsonline.com/ijeat/VOL%20V/IJAET%20VOL%20V%20ISSUE%20I%20JANUARY%20MARCH%202014/IJAETVol%20V%20Issue%20I%20Article%207.pdf>
[j_link005]: <https://ieeexplore.ieee.org/document/1542519>
[j_link006]: <https://arxiv.org/abs/1711.04322>
[j_link007]: <https://github.com/kyugorithm/TIL/blob/main/journal/PG_GAN.md>
[j_link008]: <https://github.com/kyugorithm/TIL/blob/main/journal/J006_cycleGAN.md>
[j_link008]: <https://dl.acm.org/doi/abs/10.1145/3414685.3417803>
[j_link009]: <https://arxiv.org/pdf/2004.00121.pdf>
[j_link010]: <https://github.com/kyugorithm/TIL/blob/main/journal/J007_RTUG.md>
[b_link001]: <https://medium.com/@chullino/graphical-model%EC%9D%B4%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%EC%9A%94-2d34980e6d1f>
[b_link002]: <https://github.com/kyugorithm/TIL/blob/main/Theory/RestrictedBoltzmannMachine.md>
[b_link003]: <https://github.com/kyugorithm/TIL/blob/main/Theory/MCMC.md>
[b_link003]: <https://github.com/kyugorithm/TIL/blob/main/ML_APP.md>
[b_link004]: <https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#nn-module>

[nam]: <https://github.com/namjunemy/TIL#%EC%9E%91%EC%84%B1-%EA%B7%9C%EC%B9%99>
[VL_낭독체_001.zip](https://github.com/user-attachments/files/16045170/VL_._001.zip)

![image](https://github.com/user-attachments/assets/25964d69-3b46-4566-b301-7ffb9b007a4f)



발명의 효과

자동화된 썸네일 생성으로 작업 시간 및 비용 절감
인공지능 기반 품질 평가로 일관된 고품질 썸네일 제작
다단계 필터링으로 최적의 썸네일 선정 정확도 향상
주요 인물 자동 선정으로 콘텐츠의 핵심을 효과적으로 전달
다양한 포맷 지원으로 플랫폼 호환성 확보

청구항 작성 방향

비디오로부터 썸네일을 자동 추출하는 방법
얼굴 기반 클러스터링을 통한 주요 인물 선정 방법
감정 추정 및 품질 평가 기반 썸네일 점수화 방법
레터박스/필러박스 자동 검출 및 제거 방법
다단계 필터링을 통한 최적 썸네일 선정 시스템

이 특허의 핵심적인 특허성은 다음과 같은 부분에서 찾을 수 있습니다:

다단계 필터링 시스템: 단순한 이미지 품질 평가를 넘어서 얼굴 인식, 감정 추정, 랜드마크 분석 등을 순차적으로 적용하는 복합적인 평가 시스템입니다.
얼굴 임베딩 기반 클러스터링: 코사인 유사도를 활용한 클러스터링과 자동 클러스터 수 결정은 기존 방식과 차별화됩니다.
통계적 접근의 감정 평가: 감정 벡터의 분포를 활용하여 극단적인 표정을 필터링하는 방식은 새로운 접근법입니다.





네, 말씀하신 알고리즘을 체계적으로 정리해서 설명해드리겠습니다. 이 시스템은 비디오로부터 OTT 플랫폼에 적합한 썸네일을 자동으로 추출하는 지능형 시스템이네요.

전체 알고리즘은 다음과 같은 주요 단계들로 구성됩니다:

첫째, 비디오 샷 분할 및 기초 이미지 추출 단계입니다. 전체 비디오를 효율적으로 처리하기 위해 먼저 의미 있는 샷 단위로 분할합니다. 각 샷에서 1-3장 정도의 대표 이미지를 뽑아내는데, 이때 다음과 같은 기본적인 이미지 품질 지표들을 활용합니다:

이미지의 밝기값과 그 표준편차
소벨 필터를 통한 그래디언트 분석
이미지 선명도와 블러 정도 평가
둘째, 얼굴 검출 및 품질 평가 단계입니다. 추출된 이미지들에 대해 얼굴 검출을 수행하고, 얼굴 랜드마크를 추출합니다. 이 정보를 바탕으로:

얼굴의 존재 여부 확인
눈의 크기와 개폐 상태 분석
얼굴 크기의 적절성 평가 이런 요소들을 통해 썸네일로서의 적합성을 1차적으로 판단합니다.
셋째, 얼굴 인식 및 클러스터링 단계입니다. 검출된 얼굴들에 대해:

얼굴 영역의 임베딩 벡터 추출
코사인 유사도 기반의 비지도 클러스터링 수행 (HDBScan 등 활용)
주요 인물 클러스터 식별 이를 통해 영상 속 주요 인물들을 자동으로 그룹화합니다.
넷째, 이미지 최적화 및 품질 향상 단계입니다:

레터박스/필라박스 검출 및 제거
감정 추정 모델을 통한 표정 분석
표정의 통계적 분포 평가 (극단적 표정 제외) 이 과정에서 썸네일로 부적합한 이미지들이 필터링됩니다.
마지막으로, 최종 썸네일 생성 단계입니다:

주요 인물 클러스터(2-3개)별 최적 이미지 선정
품질 점수에 따른 이미지 랭킹
가로형/세로형 포스터 형태로 변환
이 시스템의 특징은 단순한 이미지 추출을 넘어서서, 영상의 문맥을 이해하고 주요 인물의 최적의 모습을 포착하려 한다는 점입니다. 특히 통계적 접근을 통해 극단적이거나 부적절한 표정을 제외하고, 자연스러운 표정의 이미지를 선호하도록 설계된 점이 주목할 만합니다.

이렇게 도출된 썸네일들은 내부 작업자들이 최종 선택을 하는데 활용되며, 이는 완전 자동화가 아닌 반자동화 시스템으로 운영된다는 점에서 실용적인 접근이라고 볼 수 있습니다.

