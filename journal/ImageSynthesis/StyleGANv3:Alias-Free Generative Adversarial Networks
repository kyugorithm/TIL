This manifests itself as, e.g., detail appearing to be glued to image coordinates instead of the surfaces of depicted objects. 
We trace the root cause to careless signal processing that causes aliasing in the generator network. 
Interpreting all signals in the network as continuous, we derive generally applicable, small architectural changes 
that guarantee that unwanted information cannot leak into the hierarchical synthesis process. 
The resulting networks match the FID of StyleGAN2 but differ dramatically in their internal representations, 
and they are fully equivariant to translation and rotation even at subpixel scales. 
Our results pave the way for generative models better suited for video and animation.
Hierarchical conv.의 특성에도 불구하고, 전형적인 GAN의 합성 과정은 건전핮 못한 방식으로 절대 픽셀 좌표축에 의존한다. 
묘사 되어진 물체 표면 대신 
