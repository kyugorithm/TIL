# State of the Art on Neural Rendering

### Nomenclature
1. NR : Neural Rendring
2. CG : Cumputer Graphics
3. CV : Computer Visions
4. ML : Machine Learning

## Abstract 
현실같은 가상 세계를 구현하기 위한 **효율적인 렌더링**은 컴퓨터 그래픽에서 오랜 노력의 대상이었다.  
현대 그래픽 기법은 수작업 장면 표현을 통한 진짜같은 이미지 합성에 성공적인 결과들을 얻어왔다.  
그러나 모양/재질/빛 그리고 장면에서의 다른 면들에 대한 자동 생성은 여전히 도전적인 문제로 남겨져 있으며  
이러한 문제가 풀린다면 진짜같은 컴퓨터 그래픽을 통해 더 광범위하게 사용될 것이다.  

동시에, CV와 ML의 진보는 Deep generative model이라 하는 새로운 이미지 합성 및 편집 방식을 낳았다.  
NR은 **Generative ML**과 **CG의 물리적 지식**을 결합한 급격하게 발전되는 분야이다.  
(미분가능 렌더링을 네트워크 학습에 통합함으로써)  
CG와 CV에서 수많은 application을 가지면서 neural rendering은 그래픽스 커뮤니티에서 새로운 분야가 되고있다.  
본 SOTA 리포트는 neural rendering의 최근 트렌드와 application을 요약한다.  
  
제어 가능하고 진짜같은 출력을 얻기 위해 **전통 CG**와 **Deep generative model**을 결합하는 접근법에 집중한다.  
CG와 ML 컨셉에 대한 개요로 시작해서 우리는 neural rendering 접근법의 중요한 점을 논의한다.  
특히, 제어 방식, 파이프라인의 어떤 부분을 학습하는지, 명시적 제어 대 암묵적 제어, 일반화 및 확률적 대 결정론적 합성에 중점을 둔다.  
  
이 SOTA 리포트의 뒤에는 다음의 분야에 집중한다. 
1. Novel view synthesis
2. Semantic photo manipulation
3. Facial and body reenactment
4. Relighting
5. Free-viewpoint video
6. The creation of photo-realistic avatars for virtual and augmented reality telepresence
  
마지막으로, 기술의 사회적 의미에 대한 토론으로 결론을 내리고 공개 연구 문제를 조사한다.

## 1. Introduction
가상세계의 진짜같은 이미지 생성은 정교한 CG 개발의 최우선 추진 과제 중 하나다.  

CG 접근은 
1) (최신 컴퓨터 게임 생성을 가능하게 하는)실시간 렌더링부터  
2) (장편 영화에서의 사진 촬영 디지털 인간 생성을 위한) 정교한 글로벌 조명 시뮬레이션가 있다.  
두 경우에서의 주요 병목은 content 생성이다.  
Surface geometry, appearance/material, illumination 및 animation 측면에서  
기본 scene 표현을 만들기 위해 숙련된 예술가의 방대한 양의 지루하고 값 비싼 수작업이 필요하다.  
동시에, 강력한 Generative 모델이 CV와 ML에 나타나기 시작했다.  
GAN에 대한 중요한 작업은 최근 몇 년 동안 고해상도 이미지와 비디오 생성을 위한 deep generative 모델로 발전했다.  
여기서, 다른 도메인의 제어 매개 변수 또는 이미지에서 네트워크를 조절하여 합성 콘텐츠에 대한 제어를 달성할 수 있다.  
최근에는 두 영역이 합쳐져 "NR"으로 연구되고 있다. 이 용어를 사용한 최초의 출판물 중 하나는 GQN이다.  
이는 기계가 표현과 생성 네트워크를 기반으로 주변 환경을 인식하는 것을 배울 수 있게 한다.  
네트워크가 장면의 여러 이미지를 입력으로 받아들이고 정확한 occlusion으로 임의 뷰를 출력할 수 있기 때문에  
3D에 대한 암묵적 개념을 가지고 있다고 주장한다.  
암묵적인 3D 개념 대신 그래픽 파이프라인의 구성 요소를 이용하여 3D의 개념을 더 명확하게 포함하는 다양한 다른 방법들이 뒤따랐다. 
고전적인 CG는 geometry, surface properties 및 카메라와 같은 물리학의 관점에서 출발하지만, 기계 학습은 통계적인 관점에서 이루어진다.  

이를 위해 CG 생성 이미지의 품질은 채택된 **모델의 물리적 정확성에 의존**하는 반면,  
ML 접근법의 품질은 대부분 신중하게 **ML 모델과 사용된 훈련 데이터의 품질**에 의존한다.  
장면 속성의 명시적 재구성은 어렵고 오류가 발생하기 쉬우며 렌더링된 콘텐츠에 왜곡이 발생한다.  
이를 위해 이미지 기반 렌더링 방법은 간단한 경험론을 사용하여 캡처된 이미지를 결합하여 이러한 문제를 극복한다.  
그러나 복잡한 풍경에서, 이 방법들은 seams나 ghost과 같은 artifact를 보여준다.  
NR은 딥 네트워크를 사용하여 캡처된 이미지에서 새로운 이미지로의 복잡한 매핑을 학습함으로써 재구성 및 렌더링을 모두 처리할 수 있는 가능성을 제공한다.  
NR은 수학적 투영 모델과 같은 물리적 지식을 학습된 구성 요소와 결합하여 제어 가능한 이미지 생성을 위한 새롭고 강력한 알고리즘을 산출한다.  
NR은 문헌에서 아직 명확한 정의가 없다. 여기서는 NR을 다음과 같이 정의한다.  
  
_(조명/카메라/자세/geometry/외모/semantic 구조)등의 장면특성제어를  
(명시적이거나 암시적)으로 가능하게 하는 (Deep 이미지/영상 생성 접근)_  

이 SOTA 보고서는 여러 유형의 NR 방법을 정의하고 분류한다.  
이미지 생성 프로세스의 제어 가능성이 많은 CG 애플리케이션에 필수적이기 때문에 CG와 학습 기반 방식을 결합하여  
제어 가능한 이미지 생성을 위한 새롭고 강력한 알고리즘을 생성하는 방법에 초점을 맞춘다.  
이 보고서를 구성하는 한 가지 중심 계획은 각 접근법에 의해 제공되는 controllability이다. 
우리는 NR의 전제 조건인 CG, CV 및 ML의 기본 개념에 대해 논의하는 것으로 시작한다. 

이후, 제어 유형, 제어 제공 방법, 파이프라인의 학습 부분, 명시적 제어 대 암묵적 제어, 일반화 및 확률적 대 결정론적 합성과 같은 
NR 접근법의 중요한 측면에 대해 논의한다.  
다음으로, NR에 의해 활성화되는 애플리케이션의 환경에 대해 논의한다.  
NR의 응용은 새로운 시각 합성, 의미론적 사진 조작, 얼굴과 몸의 재연, 자유 시각 비디오, 가상 및 증강 현실 텔레프레전스를 위한 
사진 사실 아바타의 생성에 이르기까지 다양하다.  
실제 사진과 구별할 수 없는 이미지의 생성과 조작이 사람을 가지고 있기 때문이다.  
특히 인간이 사진에 찍힐 때, 우리는 또한 이러한 의미와 합성 콘텐츠의 탐지 가능성에 대해 논의한다.  
NR 분야는 여전히 빠르게 발전하고 있기 때문에, 우리는 현재 열린 연구 문제로 결론을 내린다.  

## 2. Related Surveys and Course Notes 

심층 생성 모델은 문헌에서 널리 연구되어 왔으며, 이를 설명하는 여러 survey와 강의 노트가 있다.  
여러 보고서는 GAN 및 VAE와 같은 특정 생성 모델에 초점을 맞추고 있다.  
고전 CG와 CV 기술을 사용한 제어 가능한 이미지 합성도 광범위하게 연구되었다.  
이미지 기반 렌더링은 여러 조사 보고서에서 논의되었다.  
Szeliski의 책은 3D 재구성 및 이미지 기반 렌더링 기술에 대한 훌륭한 소개를 제공한다.  
최근 조사 보고서는 3D 재구성에 대한 접근법과 다양한 애플리케이션의 제어 가능한 얼굴 렌더링을 논의한다.  
NR의 일부 측면은 최근 CV 컨퍼런스의 튜토리얼과 워크샵에서 다루어졌다.  
여기에는 자유 시점 렌더링 및 전신 성능의 reconstruction을 위한 접근법, 얼굴 합성을 위한 NR 튜토리얼  
및 신경 네트워크를 이용한 3D 장면 생성 등이 포함된다.  
그러나 위의 조사와 과정 중 NR과 NR의 모든 다양한 응용을 체계적이고 포괄적으로 살펴볼 수 있는 것은 없다.  

## 3. Scope of this STAR
이 최신 보고서에서는 기존의 CG 파이프라인과 학습 가능한 구성 요소를 결합한 새로운 접근 방식에 중점을 둔다. 
구체적으로, ML을 통해 고전적인 렌더링 파이프라인을 개선할 수 있는 위치와 방법과 교육에 필요한 데이터에 대해 논의하고 있다. 
포괄적인 개요를 제공하기 위해 두 분야, 즉 CG와 ML의 관련 기초에 대해서도 간략하게 소개한다. 
현재 하이브리드의 이점뿐만 아니라 한계도 보여진다. 이 보고서는 또한 이러한 기법에 의해 강화되는 새로운 응용 프로그램에 대해서도 논의한다. 
우리는 ML을 통해 제어 가능한 사실적 사진 이미지를 생성하는 것을 주요 목표로 하는 기술에 초점을 맞춘다. 
우리는 3D 재구성 및 장면 이해에 더 초점을 맞춘 기하학적 및 3D 딥 러닝에 대한 작업은 다루지 않는다. 
이 작업은 많은 NR 접근 방식, 특히 3D 구조 장면 표현을 기반으로 하지만 이 조사의 범위를 벗어난다. 
우리는 또한 ray 추적 이미지를 제거하기 위해 ML을 사용하는 기술에 초점을 맞추지 않는다.

## 4. Theoretical Fundamentals
다음에서는 NR 공간에서 작업의 이론적 기초에 대해 논의한다.  
먼저 CGI 형성 모델에 대해 논의한 다음 고전적인 이미지 합성 방법에 대해 논의한다.  
다음으로, 우리는 딥 러닝에서 생성 모델에 대한 접근법에 대해 논의한다.

### 4.1. Physical Image Formation
전통적인 CG 방법은 실제 세계에서 이미지 형성의 물리적 과정에 가깝다.  
광원은 카메라에 기록되기 전에 형상과 재료 특성의 함수로 장면의 물체와 상호 작용하는 광자를 방출한다.  
이 과정은 light transport로 알려져 있다.  
카메라 광학은 조리개로부터 들어오는 빛을 획득하여 카메라 본체 내부의 센서나 필름 평면에 초점을 맞춘다.  
센서 또는 필름은 해당 평면의 입사광의 양을 비선형 방식으로 기록한다.  
광원, 재료 특성 및 카메라 센서 등 이미지 형성의 모든 구성 요소는 파장에 따라 달라진다. 
실제 필름과 센서는 종종 인간 시각 시스템의 민감도에 맞춰 1~3개의 다른 파장 분포만을 기록한다.  
이 물리적 이미지 형성의 모든 단계(광원, 장면 형상, 재료 특성, 광전송, 광학 및 센서 동작)는 CG로 모델링된다.

### 4.1.1. Scene Representations
Scene object를 모델링하기 위해 sceone geometry에 대한 다양한 표현이 제안되었다.  
그것들은 explicit/implicit 표현으로 분류될 수 있다.  
Explicit은 장면을 삼각형, 점 같은 원시 요소 또는 고차 파라메트릭 표면과 같은 기하학적 원시 요소의 모음으로 설명한다.  
Implicit은 표면이 함수(또는 다른 수준 집합)의 영점수로 정의되는 R3 → R로부터의 부호 거리 함수 매핑을 포함한다.  
실제로 대부분의 하드웨어와 소프트웨어 renderer는 삼각형 메시에서 가장 잘 작동하도록 조정되어 있으며  
렌더링하기 위해 다른 표현을 삼각형으로 변환한다.
  
빛과 장면 표면과의 상호 작용은 표면의 재료 특성에 따라 다르다.  
재료는 BRDF(Bidirectional Reflectance Distribution Functions;양방향 반사율 분포 함수)  
또는 BSSRDF(Bidirectional Subsurface Scattering Reflectance Distribution Functions;양방향 지하 산란 반사율 분포 함수)로 나타낼 수 있다.  
BRDF는 들어오는 각 광선 방향의 표면 지점에서 발생하는 주어진 파장의 빛이 나가는 각 광선 방향을 향해 반사되는 정도를 설명하는 5차원 함수이다.  
BRDF는 단일 표면 지점에서 발생하는 빛 상호 작용만 모델링하는 반면, 
BSSDRF는 한 표면 지점에서 발생하는 빛이 다른 표면 지점에서 반사되는 방법을 모델링하여 7-D 함수를 만든다.  
BRDF는 분석 모델 또는 측정된 데이터를 사용하여 나타낼 수 있다.  
BRDF가 표면에 걸쳐 변화할 때 이를 공간적으로 변화하는 BRDF(svBRDF)라고 한다.  
기하학 전반에 걸쳐 공간적으로 변화하는 동작은 이산 재료를 다른 기하학적 원시 요소에 결합하거나 텍스처 매핑을 사용하여 나타낼 수 있다.  
텍스처 맵은 2차원 또는 3차원 도메인에서 표면으로 확산 알베도와 같은 재료 매개 변수의 연속적 값 세트를 정의한다.  
3차원 텍스처는 공간의 경계 영역을 통해 값을 나타내며 명시적이거나 암시적인 지오메트리에 적용될 수 있다. 
2차원 도메인에서 2차원 텍스처 맵 파라메트릭 지표면. 따라서 일반적으로 명시적 지오메트리에만 적용된다.

장면의 광원은 파라메트릭 모델로 나타낼 수 있으며, 빛을 방출하는 장면 표면으로 표현되는 점, 방향 조명, 영역 광원이 포함된다.  
어떤 방법은 텍스처 맵이나 함수에 의해 정의된 표면에 걸쳐 지속적으로 변화하는 방출을 설명한다.  
종종 환경 지도는 조밀하고 먼 장면 조명을 나타내기 위해 사용된다.  
이러한 환경 맵은 구나 큐브에 비모수 텍스처로 저장하거나 구면 조화 기반 계수로 근사할 수 있다.  
장면의 매개 변수는 시간이 지남에 따라 변화하는 것으로 모델링될 수 있으며,  
이를 통해 연속 프레임에 걸친 애니메이션과 단일 프레임 내에서 모션 블러 시뮬레이션을 모두 수행할 수 있다.  

### 4.1.2. Camera Models
컴퓨터 그래픽에서 가장 흔한 카메라 모델은 핀홀 카메라 모델로, 광선이 핀홀을 통과해 필름 평면(영상 평면)에 부딪힌다. 이러한 카메라는 핀홀의 3D 위치, 이미지 평면 및 센서나 필름의 공간 범위를 나타내는 평면 내의 직사각형 영역에 의해 파라미터화될 수 있다. 이러한 카메라의 작동은 균일한 좌표를 사용하여 3D 기하학적 표현을 이미지 평면의 2차원 영역으로 변환하는 투영 기하학을 사용하여 압축적으로 표현될 수 있다. 이것은 완전 투시 투영 모델이라고도 알려져 있다. 약한 투시 투영과 같은 이 모델의 근사치는 전체 투시 투영법의 비선형성으로 인해 복잡성을 줄이기 위해 컴퓨터 비전에 종종 사용된다. 컴퓨터 그래픽의 보다 정확한 투영 모델은 왜곡, 이상, 비그네팅, 디포커스 블러, 심지어 렌즈 요소들 사이의 상호반사를 포함한 비이상적 렌즈의 효과를 고려한다.

### 4.1.3. Classical Rendering
카메라, 조명, 표면 형상 및 재료를 포함한 장면 정의를 시뮬레이션된 카메라 이미지로 변환하는 과정을 렌더링이라고 합니다. 렌더링에 대한 가장 일반적인 두 가지 접근법은 래스터라이제이션과 레이트레이싱이다. 레이트레이싱은 이미지 픽셀에서 가상 장면으로 광선을 거꾸로 투사하고 기하학과의 교차점에서 새로운 광선을 재귀적으로 투사해 반사 및 굴절을 시뮬레이션하는 공정이다. 하드웨어 가속 렌더링은 메모리 일관성이 좋기 때문에 일반적으로 래스터화에 의존한다. 그러나 글로벌 조명 및 기타 형태의 복잡한 광 전송, 필드 깊이, 모션 블러 등과 같은 많은 실제 이미지 효과는 레이트레이싱을 사용하여 더 쉽게 시뮬레이션되며, 최근 GPU는 이제 실시간 그래픽 파이프라인(예: NVIDIA RTX 또는 DirectX Raytracking)에서 레이트레이싱을 사용할 수 있도록 가속 구조를 갖추고 있습니다.. 래스터화는 명시적인 기하학적 표현을 필요로 하지만, 레이트레이싱/레이캐스팅은 암묵적 표현에도 적용될 수 있다. 실제로 암묵적 표현은 행진 큐브 알고리즘 및 기타 유사한 방법을 사용하여 래스터화를 위해 명시적 형태로 변환할 수도 있다. 렌더러는 래스터라이제이션과 레이캐스팅의 조합을 사용하여 고효율과 물리적 사실감을 동시에 얻을 수 있다(예: 스크린 공간 레이트레이싱). 주어진 렌더링 파이프라인에서 생성되는 이미지의 품질은 파이프라인에 있는 다양한 모델의 정확도에 크게 좌우된다. 구성요소는 샘플링 및 신호 재구성 이론의 신중한 적용을 사용하여 픽셀 중심 사이의 간격과 같은 컴퓨터 시뮬레이션의 이산적 특성을 설명해야 한다. 새로운 뷰를 생성하거나 재료나 조명을 편집하거나 새로운 애니메이션을 만들기 위해 실제 데이터로부터 다른 모델 매개변수(카메라, 기하학, 재료, 광 파라미터)를 추정하는 과정을 역 렌더링이라고 한다. 컴퓨터 비전과 컴퓨터 그래픽의 맥락에서 탐구된 역 렌더링은 신경 렌더링과 밀접한 관련이 있다. 역 렌더링의 단점은 수학적 복잡성과 계산 비용 때문에 고전적인 렌더링에 사용되는 미리 정의된 물리적 모델이나 데이터 구조가 실제 물리적 프로세스의 모든 특징을 정확하게 재현하지 못한다는 것이다. 대조적으로, 신경 렌더링은 그러한 모델 대신 학습된 구성 요소를 렌더링 파이프라인에 도입한다. 심층 신경망은 통계적으로 그러한 물리적 프로세스를 근사화하여, 역 렌더링보다 실제 효과를 더 정확하게 재생산하여 훈련 데이터와 더 밀접하게 일치하는 출력을 생성할 수 있다. 역 렌더링과 신경 렌더링이 교차하는 지점에는 접근법이 있습니다. 예: Li 등. 는 전역 조명 효과를 근사화한 신경 렌더러를 사용하여 깊이, 정상, 반사율 및 거칠기 맵을 예측하는 역 렌더링 방법을 효율적으로 훈련합니다. 또한 신경망을 사용하여 셰이더와 같은 고전적 렌더링 파이프라인의 특정 구성 요소를 향상시키는 접근 방식도 있다. 레이너 외. 양방향 텍스처 기능과 Maximov 등을 배우세요. 모양 맵을 배웁니다.

4.1.4. Light Transport
광수송은 빛을 방출하는 광원으로부터, 장면을 통해, 그리고 카메라로 보내는 가능한 모든 경로를 고려한다. 이 문제의 잘 알려진 공식은 고전적 렌더링 방정식이다.  
![image](https://user-images.githubusercontent.com/40943064/144739258-d3599714-c0b6-44af-bca6-7c19d9c09ea9.png)  
여기서 Lo는 위치, 광선 방향, 파장, 시간의 함수로써 표면으로부터의 나가는 광도를 나타낸다. Le라는 용어는 직접 표면 방출을 나타내며 Lr이라는 용어는 입사광과 표면 반사율의 상호작용을 나타냅니다.  ![image](https://user-images.githubusercontent.com/40943064/144739268-07f6206a-7a7a-4e76-bacf-6e198ae48603.png)  
이 공식은 투명한 물체와 지표면 아래 또는 부피 산란의 영향을 고려하지 않는다. 렌더링 방정식은 적분 방정식이며, 오른쪽에 나타나는 입사 광도 Li가 같은 광선의 다른 표면에서 나오는 송신 광도 Lo와 같기 때문에 비사소적인 장면에서는 닫힌 형태로 풀 수 없다. 따라서, 방대한 수의 근사치가 개발되었다. 가장 정확한 근사치는 몬테카를로 시뮬레이션[Vea98]을 사용하여 장면을 통과하는 광선 경로를 샘플링한다. 더 빠른 근사는 우측을 한두 번 확장한 다음 재발을 차단하여 소수의 "발광"만 시뮬레이션할 수 있다. 컴퓨터 그래픽 아티스트들은 또한 비물리적 기반 광원을 장면에 추가함으로써 추가적인 바운스를 시뮬레이션 할 수 있다.

4.1.5. Image-based Rendering
3D 컨텐츠를 2D 평면에 투영하는 기존의 렌더링과 달리, 이미지 기반 렌더링 기법은 기존 이미지 세트를 일반적으로 뒤틀고 함께 합성하여 새로운 이미지를 생성합니다. 이미지 기반 렌더링은 Thies에서 볼 수 있듯이 애니메이션을 처리할 수 있지만, 가장 일반적인 사용 사례는 캡처된 뷰의 이미지 콘텐츠를 프록시 지오메트리와 추정된 카메라 포즈를 기반으로 하여 새로운 뷰로 뒤틀리는 정적 객체의 새로운 뷰 합성이다. 완전한 새 이미지를 생성하려면 여러 캡처된 뷰를 대상 뷰로 뒤틀어야 하므로 혼합 단계가 필요합니다. 일부 재료는 뷰 포인트에서 모양을 크게 바꾸기 때문에 결과 이미지 품질은 지오메트리의 품질, 입력 뷰의 수 및 배열, 장면의 재료 특성에 따라 달라집니다. 혼합 및 뷰 의존적 효과의 보정을 위한 휴리스틱 방법이 좋은 결과를 보여주지만, 최근 연구는 이러한 이미지 기반 렌더링 파이프라인의 일부를 학습된 구성 요소로 대체했다. 심층 신경망은 혼합 아티팩트와 뷰 의존적 효과에서 비롯된 아티팩트를 모두 줄이기 위해 성공적으로 사용되었다(섹션 6.2.1).
