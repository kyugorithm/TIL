## Abstract
Image-to-Image 변환은 정렬된 이미지 짝에 대한 세트의 학습세트를 사용하여 입력과 출력 이미지 사이의 mapping을 배우는 목표인 비전과 그래픽문제이다.  
그러나 많은 task에서 짝을 이룬 학습데이터를 얻는것은 매우 어렵다.   
우리는 짝을 이룬 데이터가 없는 상황에서 source 도메인 X로부터 target 도메인 Y로의 이미지를 변환하기 위한 학습방법을 제시한다.  
우리의 목표는 G(X);생성이미지와 실제 Y의 분포를 구분할수 없이 감쪽같은 mapping G : X → Y을 하는것을 배우는것이다.  

이러한 문제 정의는 매우 under-constrained 이기 때문에 우리는 G와 짝이되는 mapping F : Y → X를 적용하고  
F(G(X)) ≈ X, G(F(Y)) ≈ Y를 강제하는 **cycle consistency loss**를 적용한다.  
Qualitative result : 짝을 이룬 학습 데이터가 없는 여러 task(including collection style transfer, object transfiguration, season transfer, photo enhancement, etc)
Quantitative result : 여러 이전 방법론들과의 비교우위를 제시한다.

## Introduction

클로드 모네는 1873 년 아름다운 봄날 아르 장 퇴유 근처 센 강둑 옆에 자신의 이젤을 놓았을 때 무엇을 보았습니까 (그림 1, 왼쪽 상단)? 


컬러 사진이 발명 되었다면 맑고 푸른 하늘과 그것을 반사하는 유리 강을 기록했을 수 있습니다. 모네는 희미한 붓놀림과 밝은 팔레트를 통해 같은 장면에 대한 인상을 전달했습니다. 모네가 시원한 여름 저녁에 카시스의 작은 항구에서 일어났다면 어떨까요 (그림 1, 왼쪽 하단)? Monet 그림 갤러리를 잠시 산책하면 그가 장면을 어떻게 렌더링했을지 상상할 수 있습니다. 아마도 파스텔 색조, 갑작스런 페인트와 다소 평탄한 다이나믹 레인지가 있습니다. 그가 그린 장면의 사진 옆에 모네 그림의 나란히있는 예를 본 적이 없음에도 불구하고 우리는이 모든 것을 상상할 수 있습니다. 대신 우리는 모네 그림 세트와 풍경 사진 세트에 대한 지식을 가지고 있습니다. 이 두 세트 간의 스타일 차이에 대해 추론 할 수 있으므로 한 세트에서 다른 세트로 "번역"하면 장면이 어떻게 보일지 상상할 수 있습니다. 이 백서에서는 한 이미지 컬렉션의 특수한 특성을 캡처하고 이러한 특성을 다른 이미지 컬렉션으로 변환 할 수있는 방법을 파악하는 등 동일한 작업을 학습 할 수있는 방법을 제시합니다. 이 문제는 이미지를 이미지로 변환하는 것으로보다 광범위하게 설명 할 수 있습니다 [22], 주어진 장면 x의 한 표현에서 다른 이미지로, 예를 들어 그레이 스케일을 색상으로, 이미지를 의미 레이블로, 에지 맵을 사진으로 변환하는 이미지 . 컴퓨터 비전, 이미지 처리, 컴퓨터 사진 및 그래픽에 대한 수년간의 연구를 통해 감독 된 설정에서 강력한 번역 시스템이 만들어졌습니다. 여기에서 예제 이미지 쌍 {xi, yi} N i = 1을 사용할 수 있습니다 (그림 2, 왼쪽), 예 : [ 11, 19, 22, 23, 28, 33, 45, 56, 58, 62]. 그러나 페어링 된 훈련 데이터를 얻는 것은 어렵고 비용이 많이들 수 있습니다. 예를 들어 의미 론적 세분화 (예 : [4])와 같은 작업에 대해 몇 개의 데이터 세트 만 존재하며 상대적으로 작습니다. 원하는 출력이 매우 복잡하고 일반적으로 예술적 저작이 필요하기 때문에 예술적 스타일 화와 같은 그래픽 작업에 대한 입력-출력 쌍을 얻는 것은 훨씬 더 어려울 수 있습니다. 객체 변형 (예 : zebra↔horse, 그림 1 상단-중간)과 같은 많은 작업의 경우 원하는 출력이 잘 정의되어 있지 않습니다. 따라서 우리는 쌍을 이룬 입력-출력 예제없이 도메인 간 번역을 배울 수있는 알고리즘을 찾습니다 (그림 2, 오른쪽). 예를 들어 동일한 기본 장면의 두 가지 다른 렌더링이라고 가정하고 도메인간에 몇 가지 기본 관계가 있다고 가정하고 그 관계를 배우려고합니다. 쌍을 이룬 예의 형태로 감독이 부족하더라도 세트 수준에서 감독을 이용할 수 있습니다. 도메인 X에 한 세트의 이미지가 있고 도메인 Y에 다른 세트가 주어집니다. yˆ를 분류하도록 훈련 된 적에 의해 yˆ = G (x), x ∈ X, yˆ = G (x), x ∈ X가 이미지 y ∈ Y와 구별되지 않도록 매핑 G : X → Y를 훈련시킬 수 있습니다. 이론적으로이 목표는 경험적 분포 pdata (y)와 일치하는 yˆ에 대한 출력 분포를 유도 할 수 있습니다 (일반적으로 G는 확률 적이어야 함) [16]. 따라서 최적의 G는 도메인 X를 Y와 동일하게 분포 된 도메인 Yˆ로 변환합니다. 그러나 이러한 변환은 개별 입력 x와 출력 y가 의미있는 방식으로 쌍을 이루는 것을 보장하지 않습니다. yˆ에 대해 동일한 분포를 유도하는 매핑 G가 무한히 많습니다. 더욱이, 실제로 우리는 적대적 목표를 분리하여 최적화하는 것이 어렵다는 것을 발견했습니다. 표준 절차는 종종 모든 입력 이미지가 동일한 출력 이미지에 매핑되고 최적화가 진행되지 않는 모드 붕괴라는 잘 알려진 문제로 이어집니다. . 이러한 문제는 우리의 목표에 더 많은 구조를 추가 할 것을 요구합니다. 따라서 우리는 예를 들어 영어에서 프랑스어로 문장을 번역 한 다음 프랑스어에서 영어로 다시 번역하면 원래 문장으로 돌아 가야한다는 의미에서 번역이 "주기 일관성"이어야한다는 속성을 이용합니다. [삼]. 수학적으로 우리가 번역가 G : X → Y와 다른 번역가 F : Y → X를 가지고 있다면, G와 F는 서로 역이어야하며 두 매핑 모두 bijections 여야합니다.
What did Claude Monet see as he placed his easel by the bank of the Seine near Argenteuil on a lovely spring day in 1873 (Figure 1, top-left)? A color photograph, had it been invented, may have documented a crisp blue sky and a glassy river reflecting it. Monet conveyed his impression of this same scene through wispy brush strokes and a bright palette. What if Monet had happened upon the little harbor in Cassis on a cool summer evening (Figure 1, bottom-left)? A brief stroll through a gallery of Monet paintings makes it possible to imagine how he would have rendered the scene: perhaps in pastel shades, with abrupt dabs of paint, and a somewhat flattened dynamic range. We can imagine all this despite never having seen a side by side example of a Monet painting next to a photo of the scene he painted. Instead, we have knowledge of the set of Monet paintings and of the set of landscape photographs. We can reason about the stylistic differences between these two sets, and thereby imagine what a scene might look like if we were to “translate” it from one set into the other. In this paper, we present a method that can learn to do the same: capturing special characteristics of one image collection and figuring out how these characteristics could be translated into the other image collection, all in the absence of any paired training examples. This problem can be more broadly described as imageto-image translation [22], converting an image from one representation of a given scene, x, to another, y, e.g., grayscale to color, image to semantic labels, edge-map to photograph. Years of research in computer vision, image processing, computational photography, and graphics have produced powerful translation systems in the supervised setting, where example image pairs {xi , yi} N i=1 are available (Figure 2, left), e.g., [11, 19, 22, 23, 28, 33, 45, 56, 58, 62]. However, obtaining paired training data can be difficult and expensive. For example, only a couple of datasets exist for tasks like semantic segmentation (e.g., [4]), and they are relatively small. Obtaining input-output pairs for graphics tasks like artistic stylization can be even more difficult since the desired output is highly complex, typically requiring artistic authoring. For many tasks, like object transfiguration (e.g., zebra↔horse, Figure 1 top-middle), the desired output is not even well-defined. We therefore seek an algorithm that can learn to translate between domains without paired input-output examples (Figure 2, right). We assume there is some underlying relationship between the domains – for example, that they are two different renderings of the same underlying scene – and seek to learn that relationship. Although we lack supervision in the form of paired examples, we can exploit supervision at the level of sets: we are given one set of images in domain X and a different set in domain Y . We may train a mapping G : X → Y such that the output yˆ = G(x), x ∈ X, is indistinguishable from images y ∈ Y by an adversary trained to classify yˆ apart from y. In theory, this objective can induce an output distribution over yˆ that matches the empirical distribution pdata(y) (in general, this requires G to be stochastic) [16]. The optimal G thereby translates the domain X to a domain Yˆ distributed identically to Y . However, such a translation does not guarantee that an individual input x and output y are paired up in a meaningful way – there are infinitely many mappings G that will induce the same distribution over yˆ. Moreover, in practice, we have found it difficult to optimize the adversarial objective in isolation: standard procedures often lead to the wellknown problem of mode collapse, where all input images map to the same output image and the optimization fails to make progress [15]. These issues call for adding more structure to our objective. Therefore, we exploit the property that translation should be “cycle consistent”, in the sense that if we translate, e.g., a sentence from English to French, and then translate it back from French to English, we should arrive back at the original sentence [3]. Mathematically, if we have a translator G : X → Y and another translator F : Y → X, then G and F should be inverses of each other, and both mappings should be bijections. We apply this structural assumption by training both the mapping G and F simultaneously, and adding a cycle consistency loss [64] that encourages F(G(x)) ≈ x and G(F(y)) ≈ y. Combining this loss with adversarial losses on domains X and Y yields our full objective for unpaired image-to-image translation. We apply our method to a wide range of applications, including collection style transfer, object transfiguration, season transfer and photo enhancement. We also compare against previous approaches that rely either on hand-defined factorizations of style and content, or on shared embedding functions, and show that our method outperforms these baselines. We provide both PyTorch and Torch implementations. Check out more results at our website.
