# VNect: Real-time 3D Human Pose Estimation with a Single RGB Camera

## Abstract
단일 RGB 카메라로 안정적이 시간적으로 안정된 방식으로 글로벌 3D 골격 자세를 포착하는 첫 실시간 방법을 제시한다.  
본 방법은 **CNN 기반 pose regressor**와 **kinematic skeletal fitting**을 결합한다.  
새로운 완전 컨볼루션 포즈 formulation은 실시간으로 2D 및 3D 조인트 위치를 함께 회귀하며 맞게 자른 프레임이 필요없다.  
실시간 kinematic skeletal fitting은 CNN 출력을 사용하여 일관된 kinematic skeleton을 기반으로 일시적으로 안정적인 3D 글로벌 pose reconstruction을 산출한다.  
이는 우리의 접근 방식을 3D 캐릭터 제어와 같은 실시간 애플리케이션에서 사용할 수 있는 최초의 단일 카메라 RGB 방식으로 만들었으며,  
(지금까지는 RGB-D 카메라를 사용한 방식이 유일하다.)  
본 방법의 정확도는 최고의 오프라인 3D 단안 RGB 포즈 추정 방법과 수치적으로 동등하다.  
본 결과는 질적으로 Kinect와 같은 단안 RGB-D 접근 방식의 결과와 비교할 수 있으며 때로는 더 낫다.  
그러나 우리는 우리의 접근 방식이 RGB-D 솔루션보다 더 광범위하게 적용 가능하다는 것을 보여준다.  
즉, 실외 장면, 커뮤니티 비디오 및 저품질 상품 RGB 카메라에 작동한다.

**Summary :**
1) 단일 카메라를 통한 실시간 전체 3D skeltal pose capture 방법 제시  
2) CNN기반 pose regressor와 kinematic skeletal fitting 방법론 결합  
3) 실시간 방식은 2D, 3D를 함께 regression하며 cropped input frame이 필요 없음
4) RGB-D가 아닌 일반 RGB 카메라를 사용하면서 광범위한 적용이 가능하고 때로 성능이 더 높음  

## Introduction
**Optical skeletal motion capture**는 영화, 게임, 스포츠, 생체역학, 의학용 캐릭터 애니메이션등 응용 프로그램에서 널리 사용된다.  
**Marker suit**를 필요로 하는 상용 시스템의 한계를 극복하기 위해, 연구자들은 멀티뷰를 사용하여 보다 일반적인 상황에서  
모션을 추정하는 **marker-less motion capture** 방법을 개발했다.  
실시간 motion base 3D 게임 캐릭터 제어, 3D 가상 및 증강 현실에서의 자기 몰입, 인간과 컴퓨터 상호 작용과 같은 응용 프로그램의 인기가 높아지면서  
Microsoft Kinect와 같이 설치가 용이한 단일 depth 카메라만을 사용한 새로운 실시간 전신 모션 추정 기술이 탄생했다.  
RGB-D 카메라는 단안 포즈 재구성을 크게 단순화하는 가치가 높은 깊이 데이터를 제공한다.  
그러나 RGB-D 카메라는 햇빛 간섭으로 야외에서 종종 실패하고, 더 크고, 더 높은 전력 소비를 가지며,  
더 낮은 해상도와 제한된 범위를 가지며, 일반 카메라만큼 광범위하고 저렴하게 사용할 수 없다.  
단일 RGB 카메라의 skeletal pose estimation은 훨씬 더 어렵고 제약이 심한 문제이다.  
2D 단안 RGB 자세 추정은 널리 연구되었지만 2D 한계가 있다.  
학습 기반 판별 방법, 특히 DL 방법, 2D 포즈 추정의 최신 기술을 나타내며 이러한 방법 중 일부는 실시간 성능을 보여준다.  
3D 골격 자세의 단안 RGB 추정은 상대적으로 연구결과가 적은 훨씬 어려운 과제이다.  
불행히도 이러한 방법은 일반적으로 오프라인이며 이미지별로 3D 관절 위치를 개별적으로 재구성하는 경우가 많다.  
이는 시간적으로 불안정하고 일정한 뼈 길이를 적용하지 않는다.  
대부분의 방식은 전체 전역 3D 포즈가 아니라 bounding box에 상대적인 local 3D 포즈도 캡처한다.  
이로 인해 실시간 3D 캐릭터 제어와 같은 애플리케이션에는 적합하지 않다.  
  
본 연구에서는 일반 환경의 단일 RGB에서 실시간(30Hz)으로 안정적인 단일 kinematic skeletal의 관절각도 측면에서  
시간적으로 일관된 전역 3D 인간 자세 캡처 방법을 처음 제시한다.  

접근 방식은 CNN을 사용하여 최고 성능의 단일 RGB 3D 포즈 추정 방법을 기반으로 한다.  
높은 정확도는 부분적으로 bounding box 추출과 같은 추가 사전 처리 단계로 인해  
실시간으로 실행이 어려운 비교적 깊은 네트워크를 훈련해야 한다.  
Mehtaet은 100-layer 구조를 사용하여 2D 및 3D 관절 위치를 동시에 예측하지만 실시간 실행에는 적합하지 않다.  
Runtime 개선을 위해 더 얕은 50-layer 네트워크를 사용한다. 그러나 실시간 프레임 속도에서 최상의 품질을 위해  
더 얕은 변형을 사용하는 것이 아니라 새로운 완전 컨볼루션 공식으로 확장한다.  
이를 통해 특히 end effector(손, 발)의 보다 정확한 2D 및 3D 포즈 회귀가 실시간으로 가능하다.  
기존 솔루션과 달리 자르지 않은 이미지에 대한 작업을 수행하며 런타임이 문제인 경우 간단한 bounding box tracker를 부트스트랩하는 데 사용할 수 있다.  
또한 CNN 기반 관절 위치 회귀를 효율적인 최적화 단계와 결합하여 3D 골격을 이러한 재구성에 시간적으로 안정적인 방식으로 맞추면 골격의 전체 포즈와 관절 각도를 산출한다.  
요약하면 단일 RGB 비디오에서 전역 3D kinematic 골격 자세를 캡처하는 최초의 실시간 방법을 제안하여 기여한다.  
계산 복잡성과 정확성 사이에서 좋은 절충안을 찾기 위해 우리의 방법은 다음을 결합한다.  

• CNN을 사용하여 2D/3D 관절 위치를 동시에 산출하고 무거운 bounding box 필요성을 없애는 새로운 실시간 fully convolution 3D body pose formulation.  
  
• 2D/3D에 대한 모델 기반 kinematic skeletal fitting은 실시간으로 메트릭 글로벌 3D 골격의 시간적으로 안정적인 관절 각도를 생성하기 위한 예측을 제시한다.  
  
본 실시간 방법은 특히 end effector(S5.2)에 대해 표준 3D human body pose benchmark에서 최고의 오프라인 RGB 포즈 추정 방법에 필적하는 정확도를 달성한다.  
결과는 최신 단일 RGB-D 방법, 심지어 상용 방법과 질적으로 비교할 수 있고 때로는 더 좋다.  
이것이 게임 캐릭터 제어 또는 몰입형 1인칭 가상 현실(VR)과 같은 유사한 실시간 3D 응용 프로그램(지금까지는 RGB-D 입력으로만 가능)에  
사용할 수 있는 최초의 단일 RGB 방법을 실험적으로 보여준다.  
야외환경, 공개 비디오 및 스마트폰 카메라의 저품질 비디오 스트림과 같이 기존 RGB-D 방법이 성공하지 못하는 설정에서의 성공을 보여준다.  

## 2 RELATED WORK
**Multi view:**  
Multi-view를 통해 marker-less motion capture 방법은 더 높은 정확도를 달성한다.  
생성 이미지 형성 모델을 통해 frame-to-frame으로 수동으로 초기화된 actor 모델을 추적하는 것이 일반적이다.  
대부분의 방법은 오프라인 연산을 통해 높은 품질을 목표로 한다. 실시간 성능은 모델 대 이미지 피팅을 허용하는 공식 외에  
가우시안 및 기타 근사치로 행위자를 대표함으로써 달성할 수 있다.  
그러나 이러한 추적 기반 접근방식은 최적화하는 비볼록 피팅 함수의 국소 최소값에서 궤적을 잃는 경우가 많으며, 별도의 초기화가 필요하다.  
단일 입력 관점과 자기 중심 관점에서도 생성적 추정과 차별적 추정의 조합으로 강건성을 높일 수 있다.  
생성 추적 구성 요소를 활용하여 시간적 안정성을 보장하지만 추정 속도를 높이기 위해 전체 이미지 형성 모델을 통한 모델 투영을 피한다.  
대신, 제한되지 않은 환경에서 성공하기 위해 차별적 자세 추정과 kinematic 피팅을 결합한다.

## 3 OVERVIEW 
단안 RGB 카메라에서 인간의 시간적으로 일관된 완전한 3D 골격 포즈를 얻을 수 있다.  
3D 포즈를 추정하는 것은 고유한 모호성으로 인해 어렵고 제약이 적은 문제이다.  
그림 2는 이 어려운 문제를 해결하는 방법에 대한 개요를 제공한다.  
![image](https://user-images.githubusercontent.com/40943064/139999064-1bb7c124-7259-49b6-a90c-f05483f08b6d.png)  
두 가지 기본 구성 요소가 있다. 
첫 번째는 ill-posed 단안 캡처 조건에서 2D 및 3D 관절 위치를 회귀하는 CNN이다.  
이는 주석이 달린 3D 인간 포즈 데이터 세트에서 학습되며, 주석이 달린 2D 인간 포즈 데이터 세트를 활용하여 개선된 실제 성능을 제공한다.  
두 번째는 회귀된 관절 위치를 kinematic skeletal fitting과 결합하여 시간적으로 안정적인 카메라 기준 전체 3D 골격 포즈를 생성한다.  

**CNN Pose Regression:**:  
핵심은 실시간으로 2D 및 루트(골반) 상대 3D 관절 위치를 모두 예측하는 CNN이다.  
새로 제안된 fully conv. 자세 formulation은 3D 관절 위치 정확도에서 SOTA 오프라인 방법과 성능이 동등하다. 
완전 conv.이기 때문에 object만 자른 이미지가 필요없다.   
CNN은 상황에 관계없이 다양한 활동 클래스에 대한 관절 위치를 예측할 수 있으며  
시간적으로 일관된 전체 3D 포즈 매개변수를 생성하기 위한 추가 자세 개선을 위한 강력한 기반을 제공한다.  
  
**Kinematic Skeleton Fitting:** CNN의 2D/3D 예측 , 시퀀스의 시간 기록과 함께 카메라 공간에 국한된 골격 루트(골반)와 함께  
시간적으로 일관된 전체 3D 골격 포즈를 얻는 데 활용할 수 있다. 우리의 접근 방식은 최적화 기능을 사용한다.  
(1) 예측된 2D 및 3D 관절 위치를 결합하여 운동학적 골격을 least-square 개념에 맞춘다.  
(2) 시간 흐름에 따라 부드러운 추적을 보장한다. 다양한 단계에서 필터링 단계를 적용하여 추정 자세 안정성을 더욱 향상시킨다.  
  
**Skeleton Initialization (Optional):** 시스템은 대부분의 인간에게 기본적으로 잘 작동하는 기본 스켈레톤으로 설정된다.  
정확한 추정을 위해 초기에 몇 프레임에 대한 CNN 예측을 평균화하여 기본 골격의 상대적 신체 비율을 대상의 신체 비율에 맞출 수 있다.  
스케일 참조 없이 단안 재구성이 모호하기 때문에 CNN은 높이 정규화된 3D 관절 위치를 예측한다.  
사용자는 실제 미터법 공간에서 3D 포즈를 추적할 수 있도록 높이(머리에서 발끝까지의 거리)를 한 번만 제공하면 된다.  

**4 REAL-TIME MONOCULAR 3D POSE ESTIMATION**  
단안 RGB 입력 시퀀스에서 시간적으로 일관된 3D 골격 움직임을 추정하는 방법의 다양한 구성 요소에 대해 자세히 설명한다.  
입력으로 단안 RGB 이미지 {..., It−1, It }의 연속 스트림을 가정한다.  
입력 스트림의 프레임 t에 대해 우리 접근 방식의 최종 출력은 추적되는 사람의 전체 전역 3D 골격 포즈인 P_t^G 이다.  
이 출력은 이미 시간적으로 일관되고 전역 3D 공간이므로 문자 제어와 같은 응용 프로그램에서 쉽게 사용할 수 있다.  
방법의 중간 구성 요소에서 출력에 대해 다음 표기법을 사용한다.  
CNN 포즈 회귀자는 2D 관절 위치 **Kt**와 루트 상대 3D 관절 위치 P_t^G 를 공동으로 추정한다.  
3D 골격 피팅 구성 요소는 2D/3D 관절 위치 예측을 결합하여 카메라 공간의 전역 위치 d와 운동학적 골격 S의 관절 각도 θ에 의해 매개변수화된 부드럽고 시간적으로 일관된 포즈 PG t(θ, d)를 추정합니다. J는 관절 수를 나타냅니다. 가독성을 돕기 위해 특정 섹션에서 프레임 번호 아래 첨자 t를 삭제합니다.
