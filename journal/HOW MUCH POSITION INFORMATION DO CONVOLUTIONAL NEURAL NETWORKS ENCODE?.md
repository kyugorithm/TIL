## Abstract
FCN과 달리, CNN은 제한된 공간 범위로 로컬 필터와 관련된 가중치를 학습하여 효율성을 달성한다. 이는 필터가 무엇을 보고 있는지 알 수는 있지만 이미지에서 어디에 있는지 알 수는 없다는 것을 암시한다. 절대위치에 관한 정보는 본질적으로 유용하며, deep CNN이 이 정보를 인코딩하는 방법을 암묵적으로 배울 수 있다고 가정하는 것이 타당하다. 본 논문에서, 일반적으로 사용되는 신경망에 인코딩된 놀라운 정도의 절대 위치 정보를 드러내는 이 가설을 테스트한다. 포괄적인 실험 세트는 이 가설의 타당성을 보여주고 심층 CNN에서 위치 정보가 어디에서 파생되는지에 대한 단서를 제공하면서 이 정보가 어떻게, 어디서 표현되는지 조명한다.  

## 1. Indtroduction

CNN은 객체 분류 및 감지, 얼굴 인식, 의미 분할 및 특성 감지와 같은 많은 컴퓨터 사용 작업에서 최첨단 결과를 달성했다. 그러나 CNN은 딥러닝의 맥락에서 해석성의 결여에 대한 일부 비판에 직면해 있다.  
  
고전적인 CNN 모델은 공간 불가지론적이기 때문에 캡슐 또는 반복 네트워크를 사용하여 학습된 특징 계층 내의 상대적 공간 관계를 모델링했다. CNN이 위치 의존적 작업(예: semantic segmantation 및 saliency object detection)에서 중요한 절대 공간 정보를 캡처하는지 여부는 불분명하다. 그림 1과 같이 가장 돌출된 것으로 결정된 영역은 이미지의 중심 근처에 있는 경향이 있다. 이미지의 자른 버전에서 saliency를 감지하는 동안 시각적 특징이 변경되지 않았음에도 불구하고 most salient한 영역이 이동한다. 이미지를 해석하는 CNN 필터의 제한된 공간 범위를 고려할 때 이는 다소 놀랍다. 본 논문에서, 우리는 CNN이 실제로 의사 결정을 위한 신호로 위치 정보를 인코딩하는 것을 배울 수 있다는 가설을 가지고 일련의 무작위 테스트를 수행하여 절대 위치 정보의 역할을 검토한다. 우리의 실험은 위치 정보가 일반적으로 사용되는 제로 패딩에서 암시적으로 학습된다는 것을 보여준다. 제로패딩은 표현 학습에서 숨겨진 효과는 오랫동안 누락되었다. 이 연구는 CNN에서 학습된 feature의 특성을 더 잘 이해하는 데 도움이 되며 향후 조사를 위한 중요한 관찰과 생산적인 방향을 강조한다.  
  
이전 연구에서는 CNN의 작동 방식을 설명하기 위해 학습된 feature map을 시각화하려고 한다. 간단한 아이디어는 손실을 계산하고 입력 공간으로 역방향으로 전달하여 주어진 단위의 활성화를 최대화할 수 있는 패턴 이미지를 생성하는 것이다. 그러나 층 수가 증가하면 그러한 관계를 모델링하는 것은 매우 어렵다. 최근 연구는 시각화를 위한 non-parametric 방법을 제시한다. Deconv. 네트워크는 학습된 feature를 입력 공간에 다시 매핑하기 위해 활용되며, 그 결과는 feature map이 실제로 학습하는 패턴 유형을 드러낸다. 또 다른 연구는 등급별 활성화를 최대화하는 영역을 찾기 위해 픽셀 수준의 그레이디언트를 가중 등급 활성화 매핑과 결합할 것을 제안한다. 시각화 전략의 대안으로, 경험적 연구는 단순한 네트워크가 노이즈가 많은 라벨에 대해 0 훈련 손실을 달성할 수 있음을 보여주었다. 우리는 CNN이 학습한 특징을 연구하기 위해 무작위화 테스트를 적용하는 것과 유사한 생각을 공유한다. 그러나 우리의 작업은 이러한 기법들이 흥미로운 시각화 또는 이해만 제공할 뿐 CNN 모델에 의해 인코딩된 공간 관계를 밝혀내지 못한다는 점에서 기존 접근법과 다르다. 
  
요약하면, CNN은 완전히 연결된 종단 간 네트워크에 수반되는 엄청나게 많은 가중치를 다루는 방법으로 부상했다. 이로 인한 트레이드오프는 커널과 학습된 가중치가 이미지의 작은 하위 집합에 대한 가시성만 갖는다는 것이다. 이는 네트워크가 형태보다는 질감이나 색상과 같은 단서에 더 의존하는 솔루션을 의미하는 것으로 보인다. 그럼에도 불구하고 위치 정보는 이미지에서 물체가 나타날 수 있는 위치(예: 하늘의 새)에 대한 강력한 신호를 제공한다. 네트워크가 나타내는 특징과 함께 공간 위치를 암시적으로 인코딩하는 그러한 단서에 충분히 의존할 수 있다고 생각할 수 있다. 심층 신경망은 사물이 무엇이고 어디에 있는지 모두 학습함으로써 부분적으로 성공한다는 것이 우리의 가설이다. 이 논문은 이 가설을 테스트하고 CNN이 이미지에서 공간 배치에 대한 정보에 실제로 의존하고 예상하는 것보다 훨씬 더 많이 학습한다는 설득력 있는 증거를 제공한다.  
  
