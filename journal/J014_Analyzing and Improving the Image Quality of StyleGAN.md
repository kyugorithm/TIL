## Abstract
StyleGAN은 data-driven unconditional 생성이미지 모델링에 있어 SOTA 성능을 만든다.
본 논문은 몇 가지 고유한 아티팩트를 노출 및 분석하고 이를 해결하기 위해 **모델 아키텍처**와 **학습방법** 모두를 변경할 것을 제안한다.  
특히, 생성자 normalization을 재설계하고, PG를 재확인하고, latent->image 매핑에 있어 훌륭한 조건형성을 보장하도록 G를 정규화한다.  
이미지 품질을 향상시키고, PL 정규화는 G의 역이 훨씬 쉽게 되는 추가 이점을 만든다.  
따라서 생성된 이미지를 특정 네트워크에 안정적으로 속성을 지정할 수 있다.
또한 G가 output resolution을 얼마나 잘 활용하는지를 시각화하고 capacity 문제를 파악하여 추가 품질 개선을 위해 더 큰 모델을 교육하도록 동기를 부여한다.  
전반적으로, 개선된 모델은 기존 분포 품질 메트릭과 perceived image quality 측면에서 unconditional image modeling에서 SOTA를 재정의한다.

## 1. Introduction

GAN과같은 생성모델에 의해 생성된 이미지의 해상도와 품질은 급격히 향상되고 있고 최근 StyleGAN은 관련분야 SOTA를 찍었다.  
본 논문의 목표는 styleGAN이 가지는 고유 아티팩트를 고치고 품질을 향상하는 것이다.  
StyleGAN의 고유한 특성은 다음과 같다.  
z를 입력하는 대신 z를 mapping network인 f에 통과하여 중간 latent code인 w로 변환하는 것이다.  
그러면 합성네트워크 g에 대하여 AdaIN을 통해 레이어 각각에 대한 제어를 할 수 있는 아핀변환은 **style**을 생성한다.  
추가로, 랜덤노이즈를 합성네트워크에 공급함으로써 통계적 다양성을 촉진한다.  
해당 논문의 결과에서 확인할 수 있듯이 W는 Z보다 disentangle한 결과를 만들어냄을 알 수 있었다.  
본 논문에서는 합성 네트워크의 관점에서 관련 잠재 공간인 W에만 모든 분석을 집중한다.  
  
여러 관찰자들은 GAN으로 생성한 이미지에서 특징적인 아티팩트들을 발견했다.  
우리는 이러한 아티팩트의 두 가지 원인을 파악하고 이를 제거하는 **구조**와 및 **학습방법**의 변화를 설명한다.  
먼저, 공통적인 얼룩 아티팩트 원인을 조사하고 G가 구조상의 설계결함을 회피하도록 하는것을 찾는다.  
섹션2에서 우리는 G에서 사용하는 normalization을 재설계한다. 둘째로 고해상도 GAN학습을 안정화하는데 매우 성공적이었던  
Progressive growing과 관련된 아티팩트를 분석한다.  
우리는 학습동안의 네트워크 topology의 변경없이 PGGAN과같이 저해상도에서 고해상도로 점진적으로 변화해가며  
학습에 집중하는 방식과 동일한 목표를 달성하는 대안 설계를 제안한다.  
이 새로운 설계는 또한 생성된 이미지의 유효 해상도에 대해 추론할 수 있게 해주며,  
예상보다 낮은 것으로 밝혀져 용량 증가를 유발한다.  
  
생성계열 모델을 사용하여 만들어진 이미지의 품질에 대한 정량적 분석은 여전히 어려운 주제이다.  
FID는 Inception V3 classifier 고차원 feature 공간에서 두 분포의 밀도 차이를 측정한다.  
Precision and Recall(P&R)은 각각 교육 데이터와 유사한 생성된 영상의 백분율과 생성 가능한  
학습 데이터의 백분율을 명시적으로 정량화하여 추가적인 가시성을 제공한다.  
우리는 개선사항을 정량화하기 위해 이러한 측정 기준을 사용한다.  
  
FID와 P&R 모두 최근에 모양이 아닌 텍스처에 초점을 맞춘 것으로 나타난 classifier 네트워크를 기반으로 한다.  
따라서 측정 지표가 영상 화질의 모든 측면을 정확하게 포착하지는 못한다.  
우리는 원래 latent 공간 보간 품질을 추정하기 위한 방법으로 도입된 PPL 측정 체계가 형상의 일관성 및 안정성과  
상관관계가 있음을 관찰한다. 이를 바탕으로 우리는 원활한 매핑을 선호하고 명확한 품질 향상을 달성하기 위해  
합성 네트워크를 정규화한다.  
또한 계산 비용에 대응하기 위해 모든 정규화를 덜 자주 실행할 것을 제안하며, 효율성에 영향을 주지 않으면서  
정규화를 수행할 수 있도록 할 것을 권장한다.  

## 2. Removing normalization artifacts
먼저 Style에서 생성된 대부분의 이미지를 관찰한다. GAN은 물방울 모양의 독특한 artifact를 보여준다.  
그림 1에서 볼 수 있듯이, 최종 이미지에서 물방울이 선명하지 않을지라도 G의 중간 feature map에 나타난다.  
이상 징후는 약 64×64 해상도에서 나타나기 시작하여 모든 feature map에 나타나며 고해상도에서는 점차 강해진다.  
그러한 일관된 artifact의 존재는 D가 그것을 탐지할 수 있어야 하기 때문에 곤혹스럽다.  
  
우리는 각 feature map의 평균과 분산을 개별적으로 정규화하는 AdaIN 연산에 대한 문제를 정확히 지적하여,  
서로에 대한 특징의 크기에서 발견된 모든 정보를 잠재적으로 파괴할 수 있다.  
우리는 물방울 아티팩트가 G가 의도적으로 인스턴스 정규화를 넘어 신호 강도 정보를 숨긴 결과라고 가정한다.  
즉, 통계를 지배하는 강력하고 국부적인 스파이크를 생성함으로써 G는 다른 곳에서 원하는 대로 신호를 효과적으로 스케일링할 수 있다.  
아래 설명된 것처럼 정규화 단계를 G에서 제거하면 물방울 아티팩트가 완전히 사라진다는 연구 결과가 우리의 가설을 뒷받침한다.

### 2.1. Generator architecture revisited

재설계된 정규화를 보다 용이하게 하기 위해 먼저 StyleGAN G의 몇 가지 세부 사항을 수정한다.  
이러한 변경은 품질 지표 측면에서 자체적으로 중립적이거나 작은 긍정적인 영향을 미친다.  
그림 2a는 원래 StyleGAN 합성 네트워크 G를 보여주고, 그림 2b에서는 W와 bias를 보여주고  
AdaIN 연산을 normalization과 modulation의 두 구성 부분으로 나누어 다이어그램을 완전히 확장한다.  
이를 통해 각 상자가 하나의 style이 활성화된 네트워크 부분(style block)을 나타내도록  
개념적 회색 상자를 다시 그릴 수 있다.  
흥미롭게도 원래 StyleGAN은 style block 내에서 bias와 noise를 적용하여 상대적 영향이 현재 스타일의 크기에  
반비례하도록 한다. 이러한 작업을 정규화된 데이터에서 작업하는 스타일 블록 외부로 이동하면  
더 예측 가능한 결과를 얻을 수 있다.  
또한, 이 변경 후에 정규화 및 변조가 표준 편차에서만 작동하는 것으로 충분하다는 것을 알 수 있다(평균이 필요하지 않음).  
일정한 입력에 대한 bias, noise 및 normalization의 적용은 관찰 가능한 단점 없이 안전하게 제거될 수 있다.  
이 변형은 그림 2c에 나와 있으며 재설계된 정규화의 시작점 역할을 한다.
![image](https://user-images.githubusercontent.com/40943064/126871062-0f4038aa-c94e-4726-a226-0bffdb4ed186.png)

### 2.2. Instance normalization revisited
StyleGAN의 주요 강점 중 하나는 스타일 믹싱을 통해, 즉 추론 시 다른 latent w를 다른 레이어에 공급함으로써  
생성된 이미지를 제어할 수 있는 기능이다. 실제로 스타일 변조는 특정 피쳐 맵을 크기 또는 그 이상으로 증폭할 수 있다.  
Style mixing이 작동하려면 sample 단위로 이 증폭을 명시적으로 대응해야 한다.  
그렇지 않으면 다음 레이어는 의미 있는 방법으로 데이터에 대해 작동할 수 없다.  
스케일별 컨트롤을 희생시킬 의향이 있다면(비디오 참조), 정규화를 간단히 제거하여 아티팩트를 제거하고 FID를 약간 개선할 수 있다.  
이제 완전한 제어 능력을 유지하면서 아티팩트를 제거하는 더 나은 대안을 제안한다. 주요 아이디어는  
들어오는 feature map의 예상 통계에 근거하여 정규화하지만 명시적인 강제 적용은 하지 않는 것이다.  
그림 2c의 style block은 mod->conv.->norm으로 구성된다. 먼저 mod에 따른 conv.의 효과를 고려해 보자.  
mod는 들어오는 스타일에 기초하여 conv.의 각 입력 피쳐 맵을 스케일링하여 구현할 수 있다:  
  
![image](https://user-images.githubusercontent.com/40943064/126873381-c386e568-7451-42ec-b17e-8001fbaac55d.png)

w:original weight, w': modulated weight, si : 입력 feature map의 i번째에 해당하는 scale,  
j: 출력 feature map, k : conv.의 spatial footprint  

인스턴스 정규화의 목적은 기본적으로 convolution의 출력 피쳐 맵 통계에서 s의 효과를 제거하는 것이다.  
우리는 이 목표가 더 직접적으로 달성될 수 있다고 본다. 입력 활성화가 단위 표준 편차를 갖는 i.i.d. 랜덤 변수라고 가정한다.  
mod. 및 conv. 후 출력 활성화는 
![image](https://user-images.githubusercontent.com/40943064/126873368-da1c9e6e-3923-4ec9-8b25-97ae25ac9c03.png)   
의 표준 편차를 갖는다.  
즉, 출력은 해당 가중치의 L2 norm에 따라 스케일 조정된다.  
이후의 정규화는 출력을 단위 표준 편차로 복원하는 것을 목표로 한다.  
방정식 2에 근거하여, 각 출력 피쳐 맵 j를 1/4xj로 스케일링("변조")할 경우 이 값이 달성됩니다.  
또는, 숫자 문제를 피하기 위해 작은 상수  
![image](https://user-images.githubusercontent.com/40943064/126873353-e435d31b-a782-490b-b65a-1dde00c587eb.png)  
  
인 변환 가중치로 다시 구울 수 있다.  

이제 전체 스타일 블록을 등식 1과 3을 사용하여 가중치를 조정하는 단일 conv. 레이어로 태웠다(그림 2d).  
인스턴스 정규화에 비해 mod. 기법은 feature map의 실제 내용 대신 신호에 대한 통계적 가정을 기반으로 하기 때문에 더 약하다(??).  
유사한 통계 분석이 현대 network initializer[14, 19]에서 광범위하게 사용되어 왔지만,  
우리는 그것이 이전에 데이터 의존적 정규화를 위한 대체물로 사용되고 있다는 것을 알지 못한다.  
우리의 mod.는 또한 weight 텐서를 재측정하는 부분과 동일한 계산을 수행하는 weight 정규화와도 관련이 있다.  
이전 연구에서는 weight 정규화가 GAN 훈련의 맥락에서 유익하다는 것을 확인했다.  
우리의 새로운 디자인은 첨부 비디오에 나온 것처럼 완전한 제어성을 유지하면서 특징적인 아티팩트를 제거한다(그림3).  
FID는 대부분 영향을 받지 않지만(T1 : A, B), 정밀도에서 리콜로 현저한 변화가 있다. recall은 truncation을 통해  
정밀도로 거래될 수 있는 반면, 그 반대는 가능하지 않기 때문에 일반적으로 바람직하다고 주장한다.  
실제로 우리의 설계는 T1:B에 자세히 설명된 것처럼 그룹화된 변환을 사용하여 효율적으로 구현될 수 있다.  
방정식 3의 활성화 함수를 설명할 필요가 없도록 활성화 함수가 기대 신호 분산을 유지하도록 크기를 조정한다.  
