# StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation

## Abstract
두 영역에 대한 I2I 변환연구는 많은 성공이 있었지만 기존 방식은 모델이 많이 필요하므로  
3개 이상의 도메인을 처리하는데 제한적이며 한계를 해결하기 위해 **단일 모델**으로 여러 도메인에 대해  
I2I 변환을 수행할 수 있는 새롭고 확장 가능한 접근 방식인 StarGAN을 제안한다.  
통합 모델 아키텍처를 통해 단일 네트워크 내에서 **서로 다른 도메인을 가진 여러 데이터 세트를 동시에 교육**할 수 있다.  
이는 StarGAN의 우수한 변환 이미지 품질과 원하는 대상 도메인으로 입력 이미지를 유연하게 변환하는 새로운 기능으로 이어진다.  
우리는 얼굴 attribute 전송과 얼굴 expression 합성 작업에 대한 접근 방식의 효과를 경험적으로 입증한다.  

## 1. Introduction
I2I 변환작업은 이미지의 특정부분을 바꾸는 것이다. (e.x.,미소 > 찡그린 얼굴 / 그림 1 참조)  
<img src = "https://user-images.githubusercontent.com/40943064/133195077-8a616cdf-fc14-4105-b2e1-130fb8f6bc27.png" width=500 height=250>  
머리카락 색 변경, 에지 맵의 사진 재구성 및 풍경 이미지의 계절 변경의 결과로 GAN의 도입 이후 상당한 개선을 경험했다.  
서로 다른 도메인의 학습 데이터를 감안할 때, 이러한 모델은 도메인간 이미지를 변환방법을 배운다.  
모발 색, 성별 또는 나이와 같은 내재된 특성인 attrubute(예: 모발 색상의 경우 검은색/금발/갈색 또는 성별의 경우 남성/여성)을 의미한다.  
또한 도메인이 동일한 attribute를 공유하는 이미지 집합임을 나타낸다. 여러 이미지 데이터 세트에는 레이블이 지정된 여러 attribute가 함께 제공된다.  
CelebA : 머리카락 색, 성별 및 나이등의 속성 40개 레이블  
RaFD : '행복', '분노', '슬픔' 등 표정에 대한 8개의 레이블  
이러한 설정을 통해 여러 도메인의 속성에 따라 이미지를 변경하는 다중 도메인 I2I 변환과 같은 보다 흥미로운 작업을 수행할 수 있다.  
그림 1의 5개 열은 CelebA의 '금발', '젠더', '연령', '수염 피부'의 네 가지 도메인 번역 결과를 보여준다.  
가장 오른쪽 열에서와 같이 RaFD에 대한 훈련을 통해 학습한 기능을 사용하여 CelebA 이미지의 표정을 변경하기 위해  
CelebA 및 RaFD 이미지를 공동으로 훈련하는 등 서로 다른 데이터 세트의 여러 도메인 훈련으로 확장할 수 있다.  
  
그러나 기존 모델은 이러한 다중 도메인 이미지 변환 작업에서 비효율적이고 비효과적이다.  
이는 k 도메인 간의 모든 매핑을 학습하기 위해 k*(k-1) G를 훈련해야 한다는 사실에서 비롯된다.  
그림 2(a) 12개의 고유 G가 4개의 도메인에서 이미지를 변환하기 위해 어떻게 훈련되어야 하는지를 보여준다.  
<img src = "https://user-images.githubusercontent.com/40943064/133195421-52641469-768c-4487-a4ae-7e630bd9d7eb.png" width=400 height=350>  
얼굴형과 같은 모든 영역의 이미지에서 학습할 수 있는 전역적 특징이 존재하더라도 각 G는 전체 훈련 데이터를 완전히 활용할 수 없으며  
k 도메인 중 두 도메인에서만 학습한다. 학습 데이터를 완전히 활용하지 못하면 생성된 이미지의 품질이 제한될 수 있다.  
각 데이터 세트는 부분 라벨이 부착되어 있어 서로 다른 도메인을 공동으로 학습할 수 없으며, 우리는 이를 3.2절에서 자세히 논의한다.  
해결책으로 여러 도메인 간의 매핑을 학습할 수 있는 새롭고 확장 가능한 접근법인 StarGAN을 제안한다.  
그림 2 (b)에서 설명한 바와 같이, 우리 모델은 여러 도메인의 학습 데이터를 받아들이고 단일 생성기만을 사용하여 사용 가능한 모든 도메인 간의 매핑을 학습한다.  
아이디어는 간단하다. 고정 번역(예: 검정-금발 머리)을 배우는 대신, 우리의 G는 이미지와 도메인 정보를 모두 입력으로 받아들이고  
이미지를 해당 도메인으로 유연하게 변환하는 방법을 배운다. 도메인 정보를 나타내기 위해 레이블(예: 이진 또는 단일 핫 벡터)을 사용한다.  
학습중, 무작위로 대상 도메인 레이블을 생성하고 입력 이미지를 대상 도메인으로 유연하게 변환하도록 모델을 훈련시킨다.  
이를 통해 도메인 레이블을 제어하고 테스트 단계에서 원하는 도메인으로 이미지를 변환할 수 있다.  
도메인 레이블에 마스크 벡터를 추가하여 서로 다른 데이터 세트의 도메인 간에 공동 학습을 가능하게 하는 간단하지만 효과적인 접근 방식을 소개한다.  
제안방법은 모델이 알 수 없는 레이블을 무시하고 특정 데이터 집합에서 제공하는 레이블에 집중할 수 있도록 한다.  
이런 식으로 CelebA 이미지의 표정 합성 같은 작업을 잘 해낼 수 있다.  

**Contribution**  
• 단일 G와 D만 사용하여 여러 도메인 간의 매핑을 학습하며, 모든 도메인의 이미지에서 효과적으로 학습한다.  
• 모든 도메인 레이블을 제어할 수 있는 마스크 벡터 방법을 사용하여 다중 도메인 이미지 변환을 성공적으로 학습함을 보인다.  
• 얼굴 속성 전송 및 얼굴 표정 합성 작업에 대한 정성적/양적 결과를 제공한다.  

## 3. Star Generative Adversarial Networks
1. 단일 데이터 세트 내 다중 도메인 I2I 변환 프레임워크 설명  
2. 레이블 중 하나를 사용하여 이미지 변환을 유연하게 수행하기 위해 서로 다른 레이블 세트를 포함하는 여러 데이터 세트를 통합하는 방법논의  

### 3.1. Multi-Domain Image-to-Image Translation
목표는 여러 도메인을 매핑하는 단일 G를 학습하는것이다. 조건 입력 c에 대한 x의 y로의 변환을 학습한다.(G(x,c)->y)  
도메인 라벨 c를 무작위로 생성하여 G가 입력 이미지를 유연하게 학습하도록 한다. 마찬가지로 보조 분류기를 도입하여  
단일의 D가 여러 도메인을 제어하도록 한다. 즉, 우리의 D는 source와 도메인 레이블들에 걸쳐서 확률분포를 생성한다.  
D : x -> {D_{src}(x), D_{cls}(x)}.  
3번 그림은 제안 방법의 학습방식을 묘사한다.  
![image](https://user-images.githubusercontent.com/40943064/133928431-671b1ea5-2c82-46fe-91b6-0447d38b545e.png)  
(a) D : 1) **진짜와 가짜를 구분**하고 2) **실제이미지가 어떤 도메인에서 왔는지를 분류**한다.  
(b) G : x, c를 받아 fake 이미지를 생성한다. 목표 도메인 라벨은 공간적으로 복제되고 입력이미지와 concatenate 된다.  
(c) G : x의 원 도메인 입력과 함께 fake를 원본으로 복원하도록 한다.  
(d) G : G는 D로 하여금 진짜와 가짜를 구분하지 못하게 하며 목표 도메인으로써 분류할 수 있도록 한다.  
  
**Adversarial Loss.**  
생성이미지가 실제와 구분되지 않도록 하기 위해 adversarial loss를 도입한다.  
<img src="https://user-images.githubusercontent.com/40943064/133928641-c59894df-5dc9-4483-861a-3d953bd2396f.png" width = 600>  
여기서 G는 입력 이미지 x와 레이블 c에 대한 G(x,c)를 생성하며 D는 진짜와 가짜를 구분하려고 한다.  
이 논문에서, 우리는 Dsrc(x)는 D에 의해서 source에 대한 확률 분포를 표현하기 위해 사용한다.  
  
**Domain Classification Loss.**  
입력 x, c에 대해 x를 c 도메인 y로 변환하는것이 목표이다.  
이 조건을 달성하기 위해, D와 G를 최적화 할때 D의 최종 layer에 보조 분류 loss를 추가한다.  
즉, 목적을 아래 두개 항으로 분해한다.  
1) D를 최적화하기위해 사용하는 **실제** 이미지의 **도메인 분류 loss**  
2) G를 최적화하기위해 사용하는 **합성** 이미지의 **도메인 분류 loss**  
  
**Reconstruction Loss.**  
Class를 고려하는 부분을 제외하고 CycleGAN과 개략적으로 동일 (생략)  
  
**Full Objective.**  
![image](https://user-images.githubusercontent.com/40943064/133929841-ac7c4c2a-a846-4f46-943d-07a47091db51.png)

### 3.2 Tranining with Multiple Datasets
StarGAN의 주요 장점은 여러 유형의 여러 데이터 세트에 대해 통합하여 제어할 수 있다는 것이다.  
그러나 여러 데이터셋에서 학습할 때 문제는 레이블 정보가 각 데이터셋에 부분적으로만 있다는 것이다.  
CelebA와 RaFD의 경우, 전자는 머리카락 색과 성별과 같은 속성의 라벨을 포함하고 있지만,  
'행복하다'와 '분노하다'와 같은 얼굴 표정의 라벨을 가지고 있지 않으며, 후자는 그 반대이다.  
G(x, c)에서 입력 영상 x를 재구성할 때 original c에 대한 정보가 필요하기 때문에 문제가 있다.  
  
**Mask Vector.**
이 문제를 완화하기 위해 지정되지 않은 label을 무시하고 특정 데이터 집합에서 제공하는 명시적으로 알려진 label에  
초점을 맞출 수 있는 마스크 벡터 m을 도입한다. n차원 one-hot을 사용하여 m을 나타내며, n은 데이터셋의 수이다.  
또한, label의 통합 버전을 벡터로 정의한다.  
<img src="https://user-images.githubusercontent.com/40943064/133930096-fc4b67d7-bc56-4a55-a472-891d66397093.png" width = 600>  
알려진 label ci의 벡터는 이진 속성의 이진 벡터 또는 범주 속성의 단일 핫 벡터로 나타낼 수 있다.  
나머지 n-1 알려지지 않은 label의 경우 0 값을 할당하기만 하면 된다.  
우리의 실험에서, 우리는 CelebA와 RaFD 데이터 세트를 활용한다. 여기서 n은 2이다.  
  
**Traning Strategy.**  
여러 데이터 세트로 학습할 때 앞서 정의된 도메인 레이블 c\~를 G 입력으로 사용한다. 그렇게 함으로써 생성기는 지정되지 않은 label을 무시하고  
지정된 레이블에 초점을 맞추는 방법을 학습한다. G의 구조는 c\~ 입력만 제외하고 일반 구조와 동일하다.  
모든 데이터 세트에 대한 레이블에 대한 확률 분포를 생성하기 위해 D의 보조 분류기를 확장한다.  
그런 다음 D가 알려진 label과 관련된 분류 오류만 최소화하려고 시도하는 다중 작업 학습 설정에서 모델을 학습한다.  
이러한 설정에서 D는 CelebA와 RaFD를 번갈아 가며 학습하고 G는 두 데이터 세트의 모든 레이블을 제어하는 방법을 학습한니다.  
  
## 4. Implementation
**Improved GAN Training.**  
학습 과정을 안정화하고 높은 품질의 이미지를 얻기 위해, 우리는 Adversarial Loss.를 gradient penalty가 있는  
Wasserstein GAN 목적함수로 변형한다.  (xhat : 실제와 생성된 이미지의 쌍 사이를 따라 등균하는 샘플)
<img src="https://user-images.githubusercontent.com/40943064/133931852-a9cbef0c-f9d8-4363-90ad-43eac0dc54f1.png" width = 600>   

**Network Architecture.**  
**G** : Down sampling 2 conv.(stride=2) > 6 residual block > Up sampling 2 transposed conv.(stride=2) + Instance Norm.  
**D** : PatchGAN  + Norm. x  


## 5. Experiments
사용자 연구를 수행하여 얼굴 속성 전송에 대한 최근 방법과 비교 > 표정 합성에 대한 분류 실험을 수행  
> 여러 데이터 세트에서 I2I 번역을 학습할 수 있다는 실증적 결과를 보여줌  
### 5.1. Baseline Models
DIAT, CycleGAN, IcGAN
### 5.2. Datasets
CelebA(이미지 202,599, 특징 40, 해상도 178->128, 테스트 이미지 2000)  
RaFD(이미지 4,824, 표정 8, 해상도 256 -> 128)  
### 5.3. Training
Opt. : b1 = 0.5, b2=0.999  
Aug. : 수평 뒤집기(p=50%)
Upd. : D 업데이트 5번 > G 업데이트 1번  
Bat. : 16  
LR  : 1e-4 for 10 epochs and decrease to 0 for 10 epochs (100 for RaFD)  
Time. : 1 day for single M40  
  
### 5.4. Experimental Results on CelebA
다속성 transfer task에 대해 Baseline과 비교(여러 특성 합성을 위해 CycleGAN과 DIAT에 대해서 multi-step으로 학습 진행)  
