## Abstract
T2I 모델을 basis로 이용하여 고품질 T2V 생성모델 제안  
두가지 목표를 한번에 달성하는것은 어려움: 1) 사실적이고 시간적으로 일관된 비디오 2) 사전학습된 T2I 모델의 강력한 창조적 생성 특성  
제안: Casecased Video latent diffusion model(T2V -> temporal interpolation -> SR)  
#### Insight  
1) Rotary positional encoding과 결합된 간단한 temporal self-attention의 통합이 비디오 데이터에 내재된 temporal correlations를 적절히 포착한다는 사실을 확인.  
2) 이미지와 비디오의 공동 미세 조정 프로세스가 고품질의 창의적인 결과물을 만들어내는 데 중추적인 역할을 한다는 것을 확인  

## 1 INTRODUCTION
### Diffusion Models의 이미지 합성 분야 돌파구
DM은 이미지 합성 분야에서 주목할만한 돌파구를 이루었다. T2I 기술이 중심 무대를 차지하고 있다 이러한 성공을 바탕으로, T2V에 대한 관심이 증가하고 있으며, 영화 제작, 비디오 게임, 예술 창작과 같은 분야에서의 잠재적 응용 가능성에 의해 주도된다.  

### T2V 시스템의 도전과 대안 접근법
T2V 시스템을 처음부터 학습하는 것은 spatio-temporal joint distribution을 학습하기 위한 전체 네트워크 최적화에 막대한 계산 자원이 필요하기 때문에 상당한 도전을 안고 있다. 대안적인 접근법은 학습된 T2I 모델로부터 공간적 지식을 활용하여 동영상 데이터에 더 빨리 적응하고, 학습 과정을 가속화하여 고품질 결과를 효율적으로 달성하려는 목표를 가지고 있다. 그러나 실제로 (동영상 품질, 학습 비용, 모델 구성) 사이의 적절한 균형을 찾는 것은 여전히 어려우며, 이는 모델 아키텍처, 학습 전략 및 고품질 텍스트-비디오 데이터 세트 수집의 세심한 설계가 필요하다.  

### LaVie: 통합 동영상 생성 프레임워크
LaVie(3B 매개변수)라고 하는 통합 동영상 생성 프레임워크를 소개한다. 학습된 T2I Stable Diffusion을 기반으로 구축된 T2V 기초 모델로, 현실적이고 시간적으로 일관성 있는 동영상을 합성하는 것을 목표로 하며, 학습된 T2I 모델의 강력한 창의적 생성 특성을 보존한다.

#### Insight:  
1) 단순한 temporal self-attention과 RoPE(Rotary Positional Encoding)의 결합이 동영상 데이터에 내재된 시간적 상관 관계를 적절히 포착한다.(더 복잡한 아키텍처 설계는 생성된 결과물에 대한 시각적 개선을 미미하게만 가져온다.)
2) 공동 이미지-비디오 미세 조정은 고품질이고 창의적인 결과물을 생성하는 데 핵심적인 역할을 한다. 비디오 데이터 세트에서 직접 미세 조정을 하면 모델의 개념 혼합 능력이 심각하게 저하되어, 학습된 사전 지식이 점차 사라지는 catastrophic forgetting으로 이어진다. 또한, 공동 이미지-비디오 미세 조정은 이미지에서 동영상으로 대규모 지식 전달을 용이하게 하며, 이는 장면, 스타일, 캐릭터를 포함한다.  


