### Abstract
GAN은 random latent vector에서 사실적인 이미지를 합성한다.   
latent vector를 조작하면 합성 된 출력이 제어되지만 GAN을 사용하여 실제 이미지를 편집하면 다음의 문제가 존재  
i) 실제 이미지를 잠재 벡터로 투영하는 데 최적화가 오래걸림  
ii) 인코더를 통한 부정확 한 임베딩  

Proposal :  
1) Intermediate latent space에는 공간 차원 존재  
2) spatially variant modulation이 AdaIN을 대체  
위 방법을 통해 GAN의 속성을 유지하면서 기존 최적화 기반 방법보다 encoder를 통한 embedding을 더 정확하게 만든다.  

local editting, image interpolation와 같은 작업에서 최신 최첨단 모델을 훨씬 능가한다.  
GAN의 기존 편집 방법은 StyleMapGAN에서 여전히 유효하다.  

**What to study :**  
**Intermediate latent space, space dimension, AdaIN, embedding, ...**

GAN은 최근 급격한 발전으로 high fidelity 이미지 합성이 가능하다.
연구에 따르면 GAN은 latent space 내에서 풍부한 의미를 encoding하는 방법을 자연스럽게 학습하므로 latent code를 변경하므로써 출력 이미지의 해당 속성을 조작할 수 있게 된다.  
그러나 GAN에는 이미지에서 해당 latent code로의 inverse mapping이 없어 앞서 말한 조작을 실제로 적용하는것은 어렵다.  
**Q : inverse mapping이 왜 필요하지?**  

#### 유망한 접근방법들
Image-to-Image translation : 모델은 사용자의 입력에 따라 출력 이미지를 합성하는 방법을 학습  
그러나 이러한 방법은 모델학습을 위해 predefined task와 supervised learning을 위한 입출력 쌍을 명확하게 필요로 하며 추론 시간에 사용자 제어 가능성을 제한한다.  

Pretrained GAN 활용 : 개별 이미지에 대한 latent code를 직접 최적화  
그러나 high-end GPU에서도 각 대상 이미지에 대해 몇 분의 계산이 필요하며 최적화 된 코드가 GAN의 원래 latent space에 배치된다는 보장은 없다.  

Additional encoder train : 이미지를 해당 잠재 코드에 투영하는 방법을 학습하는 추가 인코더를 훈련  
이 접근 방식은 단일 피드 포워드 방식으로 실시간 projection을 가능하게하지만 이미지의 fidelity가 낮다.(대상 이미지 세부 정보 손실)  
이런 한계는 공간 차원이 없기 때문에 발생하는것으로 생각한다.인코더는 이미지의 로컬 의미를 얽힌 방식으로 벡터로 압축하여 이미지를 재구성하기 어렵게 만들게 된다.  
(예 : vector 기반, low-resolution bottlenect은 고주파 세부 정보를 생성 할 수 없음).  
이러한 문제에 대한 해결책으로 본 논문은 latent space의 새로운 표현으로 스타일 맵을 활용 한 StyleMapGAN을 제안한디.  

핵심 아이디어 : **벡터 기반 잠재 표현** 을 배우는 대신 **명시적인 공간 차원**을 가진 텐서를 사용한다. 이를통해 공간차원의 이점을 이용할 수 있으므로  
GAN이 이미지의 로컬 의미를 latent space로 쉽게 인코딩 할 수 있다. 이 속성을 사용하면 encoder가 이미지를 latent space로 효과적으로 projecting 하여 고화질 및 실시간 project이 가능하다.  
또한 본 방법은 stylemap의 일치하는 위치를 조작하여 이미지의 특정 영역을 편집하는 새로운 기능을 제공한다.  
<img src="https://github.com/kyugorithm/TIL/blob/main/sources/J002_F001.png" width="400" height="200">  
위 그림의 모든 편집은 실시간으로 이루어진다.  

여러 데이터 세트에서 스타일 맵은 실제로 기존 벡터 기반 잠재 표현(§4.3)에 비해 projection 품질을 크게 향상시킨다.  
또한 이미지 projection, interpolation 및 local editting (§4.4 & §4.5)에 대한 최첨단 방법보다 본 방법의 장점을 보여준다.  
추가로 본 방법은 영역이 한 이미지와 다른 이미지 사이에 정렬되지 않은 경우에도 영역을 이식 할 수 있음을 보여준다. (4.6)

#### 2. 관련연구
**Optimization based edtting** : 사전 훈련 된 GAN의 latent vector를 반복적으로 업데이트하여 실제 이미지를 latent space에 projection한다.  
예를 들어, Image2StyleGAN은 StyleGA의 각 레이어에 대한 intermediate representation을  최적화하여 이미지를 재구성한다.  
In-DomainGAN은 픽셀 공간에서 이미지를 재구성하는 것뿐만 아니라 원본 latent space의 의미론적 영역에 반전 된 코드를 착륙시키는 데 초점을 맞춘다.  
Neural Collage와 pix2latent는 이미지를 클래스 cGAN (예 : BigGAN)의 잠복 공간에 투영하기위한 하이브리드 최적화 전략을 제시합니다.  
다른 한편으로, 우리는 최적화 방법보다 2-3 배 빠르게 편집하는 인코더를 이용합니다. 학습 기반 편집 방법은 대상 이미지가 주어진 잠재 코드를 직접 추론하도록 추가 인코더를 훈련시킵니다.  
예를 들어, ALI와 BiGAN은 생성기와 역 매핑을 공동으로 학습하기 위해 완전히 적대적인 프레임 워크를 도입합니다.  
잠복 투영을 위해 변이 형 자동 인코더를 GAN과 결합하기위한 몇 가지 작업이 이루어졌습니다. ALAE는 StyleGAN의 중간 잠재 공간을 예측하는 인코더를 구축합니다.  
그러나 위의 모든 방법은 잠재 공간의 공간적 차원이 부족하기 때문에 제한된 재구성 품질을 제공합니다.  
Swap Autoencoder는 이미지를 구조 코드와 텍스처 코드의 두 가지 구성 요소로 인코딩하고 모든 스왑 조합이 주어지면 사실적인 이미지를 생성하는 방법을 학습합니다.  
이러한 표현 덕분에 이미지를 빠르고 정확하게 재구성 할 수 있지만 텍스처 코드는 여전히 벡터이므로 구조화 된 텍스처 전송이 어렵습니다.  
우리의 편집 방법은 색상과 질감뿐만 아니라 참조 이미지의 모양도 성공적으로 반영합니다.  
