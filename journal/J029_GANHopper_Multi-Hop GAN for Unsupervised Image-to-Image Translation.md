## Abstract. 
여러번의 hop을 통해 두 도메인간 이미지를 점진적으로 변화하는 방법을 제안한다.  
변환을 직접 실행하는 대신 입력 도메인의 이미지 간 weigthed-hybrid와 유사한 중간 이미지를 생성하도록 요구하여 번역을 조정한다.  
네트워크는 중간 이미지 없이 두 도메인의 페어링되지 않은 이미지에 대해서만 훈련된다.  
모든 hop은 각 방향을 따라 단일의 G를 사용하여 생성된다.  
Cyc. loss와 Adv. Loss 외에도 새로운 hybrid D를 도입하여 G에 의해 생성된 중간 이미지를  
사전정의된 hop 수를 기반으로 하는 가중치를 사용하여 가중 하이브리드로 분류하도록 학습되었다.
또한 각 hop의 magnitude를 제한하는 smootheness 항을 추가하여 변환을 더욱 정규화한다.  
이전 방법과 비교하여 GANHopper는 도메인별 이미지 feature 및 geometry 변환과 관련된  
이미지 변환에 탁월하며 색상 구성과 같은 도메인과 무관한 feature도 보존한다.

## 1. Introduction

기존 방법론(CycleGAN, DualGAN)은 개/고양이 변환 같은 geometry and shape이 어렵고 pixel색상/texture 변환만 가능하다. (그림1)  
도메인간 차이가 클수록 복잡하고 어려우며 pair 이미지를 지도 학습하지 않고는 변환에 대한 탐색공간은 거대할 수 있다.   
큰 이미지 변환으로 설명할 자유도는 더 높기 때문에 더 **큰 제약**을 가하고 더 **조절 가능한 탐색**이 필요하다.  
본 논문에서는 개고양이와 같은 도메인 사이에서 점진적으로 이미지를 변환하도록 제약하는 이미지 변환 방법을 제안한다.  
직접변환을 수행하는 것 대신에, hop이라 표현하는 단계별 task를 수행한다.  
본 multi-hop network 구조는 CycleGAN으로 구성된다.  
대신 두 입력 도메인의 이미지 간의 weighted hybrid와 유사한 이미지를 생성하도록 강제하여 번역 경로를 조정한다.  
예를 들어 4-hop 네트워크를 이용하여 25%/75%, 50%/50%, 75%/25%의 개/고양이 이미지를 생성한다. 마지막 단계는 100% 변환된 고양이 이미지가 된다.  
GANHopper는 학습 세트에 중간 하이브리드 이미지가 없이도 unpaired 세팅으로 학습이 가능하다.  
또 중요한 것은 모든 hop이 각 방향을 따라 단일 G를 사용하여 생성되므로 네트워크 용량이 CycleGAN의 용량을 초과하지 않는다는 것이다.  

학습을 가능하게 하기 위해 이미지에 대해서만 훈련되어 정의한 hop 수에 따라 가중치 하이브리드로 분류하여 중간 이미지를 평가하는 새로운 hybrid D를 도입한다.  
CycleGAN의 기존 loss에 아래 loss 두개를 추가한다.  
1.	**Hybrid loss**: 이미지가 입력 도메인 중 하나에 속하는 정도(%)를 평가  
2.	**Smoothness loss** : hop 시퀀스에서 생성된 이미지가 이전 이미지에서 크게 차이나지 않도록 이미지 전환을 조절  
GANHopper는 단순히 입력 고양이를 개로 변환하지 않는다. 다양한 개의 모습이 D를 속일 수 있지만 특히   
주어진 고양이와 비슷한 개를 생성하는 것을 목표로 한다. (그림1)  

본 방법론은 기존 방법론과 비교하여 도메인별 이미지 특징 및 geometry 변형과 관련된 이미지 번역에서 탁월함과 동시에  
털 색상과 같은 같은 도메인에 무관한 이미지 특징을 보존할 수 있다 (그림1).  
감독되지 않은 도메인 변환을 통해 기하 변형과 같은 큰 변화를 생성하는 능력은 가장 많이 추구되는 문제였다.  
원래 CycleGAN/DualGAN 구조는 geometry 변형을 학습할 수 없다는 일반적인 생각이 있어왔으며 변환을 위해서는 feature 표현,  
학습 방법을 바꿔야만 했다. 그 결과 많은 접근방법이 latent 공간변환(style-content, scale 분리, feature disenglement)에 집중해왔다.  
GANHopper는 이미지 공간에서 직접 작동하는 CycleGAN과 근본적으로 동일한 아키텍처를 따르기 때문에 앞선 믿음에 반하는 도전적인 연구이다. 
이를 달성하기 위해 **변환 정도를 조정**하고 **점진적인 다중 hop 변환**을 시행할 뿐이다.  
또한, 다중 hop GAN은 예를 들어 중간 번역기의 수와 아키텍처를 변경하는 측면에서 상당히 확장 가능한 일반적인 "meta idea"를 나타낸다.  
그림 1 및 이후의 더 많은 결과에서 알 수 있듯이 하나의 네트워크를 사용하는 가장 간단한 옵션이라도  
이미 다양한 도메인 번역 작업에서 상당한 차이를 만들 수 있다.  
  
![image](https://user-images.githubusercontent.com/40943064/135719899-96a37beb-4319-44a7-a50a-9a3bd3c7d794.png)

  
## 2 Related Work
**2.1 Supervised Setting**
현대 이미지-이미지 변환의 기초는 semantic image segmentation을 위해 처음 개발된 UNet 이다.  
이는 나중에 조건부 적대 훈련을 통해 다양한 I2I 변환 작업으로 확장되었다.  
추가 연구로 "one to many" 변환 작업에서 동일이미지에 대해 고해상도 출력과 여러 가능한 출력(e.x., grey-scale image colorization)이 생성되었다.  
이 방법은 학습 데이터로 쌍을 이루는 입력 및 출력 이미지 {(xi , yi)}가 필요하다.  
**2.2 Unsupervised Setting**
최근의 I2I 변환 네트워크는 입력/출력 이미지의 두 세트 {xi} 및 {yi}의 형태로 쌍을 이루지 않은 데이터에서 학습할 수 있다.  
이러한 방법은 G를 함께 학습하여 x에서 y로 매핑하고 네트워크 F를 y에서 x로 매핑하여 훈련 시간에 F(G(x)) = x 및 G(F(y)) = y를 적용한다.  
이러한 cycle-consistency는 학습된 매핑을 임의의 번역이 아니라 semantically meaning한 것으로 정규화하는 것으로 생각된다.  
이 방식은 약한 변환(예: 여름에서 겨울, 낮에서 밤)과 관련된 도메인 번역에서는 성공하지만 큰 형태 변형이 필요한 경우(예: 고양이에서 강아지로) 종종 실패한다.  
cycle-consistency를 포함하는 네트워크는 더 전역적인 이미지 컨텍스트를 고려하는 D와 perceptual loss로 학습될 때 더 큰 모양 변화를 수행하는 것으로 나타났다[5].  
다른 접근 방식은 두 도메인의 이미지가 생성되는 공유 잠재 코드 z를 삽입하는 것이다(x = F(z) & y = G(z)) [15].  
이 방법을 확장하여 여러 출력 이미지로 번역할 수도 있다[7].  
또 다른 방법은 geometry와 appearance를 명시적으로 별도로 모델링하는 것이다.  
사람의 얼굴을 캐리커처 스케치로 변환하는 영역별 방법은 얼굴 랜드마크를 감지하고 변형한 다음 입력 얼굴을 왜곡하는 데 사용하여 이를 수행한다[2].  
보다 최근의 연구는 얼굴에만 국한되지 않는 관련 기술을 제안했다[24].  
마지막으로 사전 훈련된 이미지 분류 네트워크의 특징 계층을 통해 도메인 변환을 수행하는 것도 가능하다[10].  
이 방법은 또한 큰 모양 변화를 일으킬 수 있다.  

**2.3 본 방법론**
위와 대조적으로, 우리는 변환이 일련의 smooth hopping으로 수행되는 경우 직접 I2I 변환이 모양 세부 사항을 보존하면서 큰 모양 변경을 생성할 수 있음을 보인다.  
이 과정은 도메인간 interp. 시퀀스를 생성하는 것으로 볼 수 있다. 많은 GAN은 latent space에서 linear interp.를 통해 이미지 사이에 보간을 생성할 수 있다.  
이러한 보간은 데이터 세트[12]에 지정되거나 자동으로 추론되는[4] 해석 가능한 방향을 따를 수도 있다. 그러나 GAN latent interp.는 교차 영역 보간을 수행하지 않는다.  
Aberman et al. [1] 두 도메인의 이미지에서 해당 지점을 식별하고 이 지점을 입력으로 사용하여 이미지 모핑을 구동하여 교차 도메인 interp.을 수행한다[13].  
그러나 이 접근 방식은 source 및 target 도메인 모두에 있는 이미지를 interp.해야 하는 반면, 우리의 방법은 소스 이미지만 가져와 가장 일치하는 대상 이미지에 대한 interp.을 생성한다.  
마지막으로 InstaGAN[18]은 한 번에 하나의 인스턴스를 변환하기 위해 분할 마스크에 의존하는 다중 인스턴스 변형 네트워크를 사용하여 바지에서 치마로의 큰 모양 변경을 처리한다.  
구현에는 다른 목적을 위한 순차적 미니배치 추론/훈련 옵션이 포함된다.  

## 3. Method
Source 도메인 X, target 도메인 : Y  
목표는 x ∈ X가 주어졌을 때 y0이 데이터 세트 Y의 이미지 x에 대응하는 것으로 인식되도록 다른 이미지 y0 ∈ Y를 출력하는 변환을 배우는 것이다.  
y ∈ Y에서 x0 ∈ X로의 아날로그 변환에서도 동일한 작업이 수행되어야 한다. 이 작업은 CycleGAN에서 수행한 작업과 동일하다[28].  
그러나 우리는 네트워크를 통해 한 번에 입력 이미지를 번역하지 않는다. 오히려 일련의 중간 이미지를 통해 번역 프로세스를 용이하게 한다.  
우리는 G를 사용하여 제한된 양만큼 하나의 이미지를 대상 도메인으로 warping하는 프로세스로 정의하는 hop의 개념을 소개한다.  
반복된 hop은 번역 프로세스의 부산물로 하이브리드 이미지를 생성한다. 네트워크를 통한 단일 패스로 이미지를 번역하지 않기 때문에  
학습 프로세스는 전통적인 cycle-consistency 학습 프레임워크에서 수정되어야 한다. 특히, 학습 데이터에 이러한 이미지가 포함되어 있지 않기 때문에  
번역 중에 하이브리드 이미지를 생성하는 것은 어려운 일이다. 따라서 이러한 생성된 이미지의 혼성성은 훈련 중에 즉석에서 추정되어야 한다.  
이를 위해 우리는 hybrid-D라고 하는 새로운 D를 도입한다. 이 D는 이미지가 두 입력 도메인과 얼마나 유사한지를 평가하여 멤버십 점수를 생성하는 것이다.  
또한 smoothness loss를 추가한다. 목적은 G가 번역을 초과하지 않도록 hop을 통해 이미지의 점진적인 warping을 장려하는 것이다.  
다음 하위 섹션에서는 다중 hop 프레임워크를 제공한다.

### 3.1 Multi-hop framework
G와 F로 표시되는 CycleGAN의 원래 두 개의 G와 세 개의 D로 구성되며, 그 중 두 개는 CycleGAN의 원래 DY, DX이다.  
세번째는 새로운 하이브리드 판별자 DH이다. 그림 2는 학습 시간 동안 이러한 다양한 G/D가 함께 작동하여 다중 hop을 통해 이미지를 번역하는 방법을 보여준다.  
![image](https://user-images.githubusercontent.com/40943064/135719910-6d44b2a5-2728-4499-a5c8-5f85067e9514.png)  


**Hop nomenclature.**  
G 혹은 F를 사용하여 이미지를 각각 Y 또는 X 영역으로 warping하는 것으로 정의된다.  
완전한 변환은 동일한 G를 사용하여 사전 정의한 h회의 hop을 수행함으로써 달성된다.  
E.x.,  
h = 3, G(G(G(x))) = y' , 여기서 x ∈ X 및 y' ∈ Y 입니다. 유사하게, F(F(F(y))) = x' , 여기서 y ∈ Y 및 x' ∈ X.  
이미지 i가 주어지면 변환 hop은 다음 반복 관계를 통해 정의된다.
![image](https://user-images.githubusercontent.com/40943064/135717509-3f1c5c4d-4f65-4b15-b038-07e72122f3f0.png)

**Generator Architecture.**  
CycleGAN에서 사용되며 Johnson[9]이 제안한 architecture 및 layer nomenclature를 채택한다.  
**c7s1-k** : [conv : 3x3 Conv-IN-ReLU / filter:k / stride:1],   
**dk** : [conv. : 3x3 Conv-IN-ReLU / filter : k / stride : 2] (Reflection padding을 통해 artifact를 줄임)  
**Rk** : [conv. : ResidualBlock with 3x3 Conv / filter : k] 
**uk** : [conv. : 3x3 TransposeConv.-IN-ReLU / filter : k / stride : 1/2]  
128×128 이미지를 입력으로 받고 c7s1-64, d128, d256, R256(×12), u128, u64, c7s1-3 레이어로 구성된다.  

**Discriminator architecture.**   
DY, DX, DH에 대해 CycleGAN에서 사용된 것과 동일한 70x70 PatchGAN[8]을 사용한다.  
**Ck** : [conv. : 4x4 Conv-IN-LearkyReLU / filter : k / stride : 2]  
128×128 입력 이미지가 주어지면 16×16 특징 행렬을 생성한다.  
각 요소는 입력 이미지의 70x70 패치 중 하나와 연결된다.  
D는 C64, C128, C256, C512 레이어로 구성된다.  

### 3.2 Training
전체 loss는 아래 4개 항을 합한것과 같다.  
![image](https://user-images.githubusercontent.com/40943064/135719004-6a723fae-7988-4f31-a035-0bdffc3c7415.png)  
(γ = 10, e= 1, δ = 1, ζ = 2.5)  

**Cycle Consistency Loss.**  
CycleGAN에서처럼 입력 이미지와 출력 이미지 사이에 주기 일관성을 적용하는 대신 다중 hop 변환의 모든 hop을 따라 로컬로 적용한다.  
즉, F는 G의 단일 홉을 실행 취소해야 하며 그 반대의 경우도 마찬가지이다.  
모든 홉 n에 대해 F(Gn)과 Gn−1의 차이에 비례하는 손실을 통해 이 속성을 적용한다.  
![image](https://user-images.githubusercontent.com/40943064/135719139-8f06e374-fa54-4c80-b8b1-f5194f39489e.png)  

**Adversarial loss.**  
G는 도메인 Y의 이미지와 유사하게 보이는 이미지 Gn(x)를 생성하려고 시도하는 반면 DY는 생성된 이미지와 실제 이미지 y ∈ Y를 구별하는 것을 목표로 한다.  
"생성된 이미지"에는 최종 출력 이미지와 중간 이미지가 모두 포함됩니다. D는 MSE를 사용한다[17].  
![image](https://user-images.githubusercontent.com/40943064/135719268-a61cb846-6e58-46fa-a8ba-de4e41bfb7f6.png)  

**Hybrid loss.**  
이미지가 두 영역 중 하나에 속하는 정도를 평가한다.  
예를 들어, 4개의 hop으로 학습된 경우 첫 번째 hop G1(x)이 도메인 Y에 25%, 도메인 X에 75% 속하는 것으로 판단되기를 원한다.  
따라서 홉 Gn의 목표 하이브리드 점수를 다음과 같이 정의한다. n/h;  
반대로, 역 홉 Fn에 대해 (h - n)/h로 정의된다. 각 홉이 목표 하이브리드를 달성하도록 장려하기 위해  
목표 하이브리드와 해당 hop의 하이브리드 판별기 DH 출력 사이의 거리에 페널티를 적용한다.  
DH는 X의 실측 이미지에 대해 0을 출력하고 Y의 실측 이미지에 대해 1을 출력하도록 훈련되었기 때문에  
DH(i)가 0.25의 출력을 생성하는 이미지 i는 다음과 같을 수 있다.  
분류자가 25% 확신하는 이미지로 해석하면 도메인 Y에 속한다.  
![image](https://user-images.githubusercontent.com/40943064/135719348-ec1704b4-775f-4452-9fa1-6d893e3bf8c7.png)  

**Training procedure.**  
알고리즘 1은 GANHopper를 훈련하는 방법을 보여준다. 즉, 번역할 각 이미지에 대해 단일 hop을 수행하고,  
G 및 D 가중치를 업데이트하고, 다음 hop을 수행하는 등이다.  
모든 홉을 수행하는 대신 이러한 방식으로 네트워크를 학습한다.  
그런 다음 단일 가중치 업데이트를 수행하면 훨씬 적은 메모리가 필요하다는 이점이 있다.  
각 특정 hop에 대해 하나의 특수 G를 사용하면 메모리 사용량이 상당히 증가하여 hop 수에 따라 선형적으로 확장된다.  
**generator_update**, **discriminator_update** 업데이트 절차는 loss L을 정의하는 합계의 단일 항(즉, 홉 n에 대한 항)을 사용하여 파라미터 gradient를 계산한다.  
![image](https://user-images.githubusercontent.com/40943064/135719443-5928d365-8797-4cf9-9566-7887384df7ca.png)  

## 4 Results and Evaluation
![image](https://user-images.githubusercontent.com/40943064/135719882-8a8a5506-be3d-4263-bfe4-76a17c13f8cf.png)  
![image](https://user-images.githubusercontent.com/40943064/135720559-874bf403-da68-4f10-8d38-35330d71e4d0.png)  


## 5 Conclusion and Future Work
### 5.1. Conclusion
Unsupervised I2I translation은 ill-posed(불량조건) problem이다. 기존에는 해결을 위해 정규화 가정을 제안했다[24,15,7].  
이 논문에서 CycleGAN[28] 및 DualGAN[25]의 cycle-consistency를 따르고 새로운 하이브리드 D를 사용하여  
변환을 세밀하게 제어하기 위해 다중 hop 패러다임을 도입한다.  
Section 4에 제시된 정량적 분석 및 인간 평가 실험 모두에서 볼 수 있듯이 GANHopper는 입력 이미지의 기능을 더 잘 보존하는 동시에  
필요한 변환을 적용하여 분명히 대상 도메인에 속하는 출력을 생성함으로써 다른 기준 접근 방식보다 성능이 뛰어나다.  

### 5.2. Future Work
"작은 단계로 이미지 변환"이라는 메타 아이디어는 탐구할 가치가 있는 새롭고 흥미로운 질문을 제기한다.  
예를 들어 '몇 단계가 이상적일까?' 이 문서의 결과에서는 2-4개의 hop을 사용했는데, hop이 많을수록  
성능이 눈에 띄게 향상되지는 않지만 학습 시간이 늘어나기 때문이다.  
그러나 도메인 X의 일부 이미지는 분명히 다른 도메인 Y로 번역하기가 더 어렵다(예: 주둥이가 긴 개와 짧은 주둥이가 있는 개를 고양이로 번역).  
각 입력 이미지에 대한 이상적인 h를 자동으로 학습할 수 있는가? 극단적으로 말하자면, source에서 target으로 smooth interp.  
시퀀스를 생성하기 위해 매우 많은 수의 작은 홉을 사용할 수 있는?  
또한 GANHopper가 체계적으로 실패하는 도메인을 식별하고 이에 대한 응답으로 다중 홉 번역 아키텍처의 설계 공간을 탐색하고자 한다.  
예를 들어, GANHopper는 모든 홉에 대해 동일한 네트워크를 사용하지만 hop당 다른 네트워크를 사용하는 것이 더 나을 수 있다.  
즉, 1(25% dog -> 50% dog) 변환의 최적은  2(75% 개와 실제 개)를 변환하는 최적과 동일하지 않을 수 있다.  
GANHopper를 MUNIT[7] 또는 BiCycleGAN[29]의 아이디어와 결합하여 사용자가 "스타일" 코드를 통해 번역의 출력을 제어하면서 중요한 입력 기능(예: 흰 고양이를 다른 흰 털 개 품종).  
또 다른 잠재적인 미래 작업은 현재 hop 정보를 G 입력(예: one-hot vector)의 일부로 포함하여 G에 의존하여  
입력 이미지에만 기반하여 어떤 hop 작업을 수행해야 하는지 추론하는 것을 방지하는 것이다.  
마지막으로, 처음에 GANHopper의 개발에 박차를 가한 아이디어를 조사하고자 한다.  
즉, 주어진 이미지 영역의 경계를 넘어 의미 있는 외삽 시퀀스를 생성하여 창의적이고 참신한 출력을 생성하는 것이다.


