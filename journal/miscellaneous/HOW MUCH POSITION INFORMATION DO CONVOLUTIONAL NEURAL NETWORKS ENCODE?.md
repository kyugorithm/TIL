## Abstract
FCN과 달리, CNN은 제한된 공간 범위로 로컬 필터와 관련된 가중치를 학습하여 효율성을 달성한다. 이는 필터가 무엇을 보고 있는지 알 수는 있지만 이미지에서 어디에 있는지 알 수는 없다는 것을 암시한다. 절대위치에 관한 정보는 본질적으로 유용하며, deep CNN이 이 정보를 인코딩하는 방법을 암묵적으로 배울 수 있다고 가정하는 것이 타당하다. 본 논문에서, 일반적으로 사용되는 신경망에 인코딩된 놀라운 정도의 절대 위치 정보를 드러내는 이 가설을 테스트한다. 포괄적인 실험 세트는 이 가설의 타당성을 보여주고 심층 CNN에서 위치 정보가 어디에서 파생되는지에 대한 단서를 제공하면서 이 정보가 어떻게, 어디서 표현되는지 조명한다.  

## 1. Indtroduction

CNN은 객체 분류 및 감지, 얼굴 인식, 의미 분할 및 특성 감지와 같은 많은 컴퓨터 사용 작업에서 최첨단 결과를 달성했다. 그러나 CNN은 딥러닝의 맥락에서 해석성의 결여에 대한 일부 비판에 직면해 있다.  
  
고전적인 CNN 모델은 공간에 불가지론적이기 때문에 캡슐 또는 recurrent 네트워크를 사용하여 학습된 feature layer 내의 상대적 spatial 관계를 모델링했다. CNN이 위치 의존적 작업(예: semantic segmantation 및 saliency object detection)에서 중요한 절대 position information을 캡처하는지 여부는 불분명하다. 그림 1과 같이 가장 돌출된 것으로 결정된 영역은 이미지의 중심 근처에 있는 경향이 있다. Crop 버전에서 saliency를 감지하는 동안 시각적 특징이 변경되지 않았음에도 불구하고 most salient 영역이 바뀐다. 이미지를 해석하는 CNN 필터의 제한된 공간 범위를 고려할 때 이는 다소 놀랍다. 본 논문에서, 우리는 CNN이 실제로 의사 결정을 위한 신호로 위치 정보를 인코딩하는 것을 배울 수 있다는 가설을 가지고 일련의 무작위 테스트를 수행하여 절대 위치 정보의 역할을 검토한다. 우리의 실험은 위치 정보가 일반적으로 사용되는 제로 패딩에서 암시적으로 학습된다는 것을 보여준다. 제로패딩은 표현 학습에서 숨겨진 효과는 오랫동안 누락되었다. 이 연구는 CNN에서 학습된 feature의 특성을 더 잘 이해하는 데 도움이 되며 향후 조사를 위한 중요한 관찰과 생산적인 방향을 강조한다.  

![image](https://user-images.githubusercontent.com/40943064/157381081-26874416-f0e8-4ea5-9dd8-2ca4964634ff.png)
  
이전 연구에서 CNN의 작동 방식을 설명하기 위해 학습된 feature map을 시각화하려고 한다. 간단한 아이디어는 loss를 계산하고 입력 공간으로 역방향으로 전달하여 주어진 단위의 활성화를 최대화할 수 있는 패턴 이미지를 생성하는 것이다. 그러나 layer가 증가하면 관계를 모델링하는 것은 매우 어렵다. 최근 연구는 시각화를 위한 non-parametric 방법을 제시한다. Deconv. 네트워크는 학습된 feature를 입력 공간에 다시 매핑하기 위해 활용되며, 그 결과는 feature map이 실제로 학습하는 패턴 유형을 드러낸다. 또 다른 연구는 등급별 활성화를 최대화하는 영역을 찾기 위해 픽셀 수준의 그레이디언트를 가중 등급 활성화 매핑과 결합할 것을 제안한다. 시각화 전략의 대안으로, 경험적 연구는 단순한 네트워크가 노이즈가 많은 라벨에 대해 0 훈련 손실을 달성할 수 있음을 보여주었다. 우리는 CNN이 학습한 특징을 연구하기 위해 무작위화 테스트를 적용하는 것과 유사한 생각을 공유한다. 그러나 우리의 작업은 이러한 기법들이 흥미로운 시각화 또는 이해만 제공할 뿐 CNN 모델에 의해 인코딩된 공간 관계를 밝혀내지 못한다는 점에서 기존 접근법과 다르다. 
  
요약하면, CNN은 완전히 연결된 end-to-end 네트워크에 수반되는 엄청나게 많은 가중치를 다루는 방법으로 부상했다. 이로 인한 트레이드오프는 커널과 학습된 가중치가 이미지의 작은 하위 집합에 대한 가시성만 갖는다는 것이다. 이는 네트워크가 형태보다는 질감이나 색상과 같은 단서에 더 의존하는 솔루션을 의미하는 것으로 보인다. 그럼에도 불구하고 위치 정보는 이미지에서 물체가 나타날 수 있는 위치(예: 하늘의 새)에 대한 강력한 신호를 제공한다. 네트워크가 나타내는 featured와 함께 spatial position을 암시적으로 인코딩하는 그러한 단서에 충분히 의존할 수 있다고 생각할 수 있다. 심층 신경망은 object가 무엇이고 어디에 있는지 모두 학습함으로써 부분적으로 성공한다는 것이 우리의 가설이다. 논문은 이 가설을 테스트하고 CNN이 이미지에서 공간 배치에 대한 정보에 실제로 의존하고 예상하는 것보다 훨씬 더 많이 학습한다는 설득력 있는 증거를 제공한다.  
  
## 2. Position information in CNNs
CNN은 자연스럽게 초기 컨볼루션 단계에서 미세한 수준의 높은 공간 주파수 세부 정보(예: 에지, 텍스처, 선)를 추출하려고 노력하며, 인코딩의 가장 깊은 계층은 가능한 가장 풍부한 category specific feature 표현을 생성한다. 본 논문에서는 position information이 추출된 feature map 내에 암시적으로 인코딩되어 시각적 장면에서 객체를 분류, 감지 또는 분할하는 데 중요한 역할을 한다는 가설을 제안한다. 따라서 우리는 종단 간 방식으로 다른 CNN architype의 position information을 예측하여 이 가설을 증명하는 것을 목표로 한다. 다음 섹션에서는 먼저 문제 정의에 대해 소개하고 제안된 위치 인코딩 네트워크에 대해 간략하게 논의한다.

#### Problem formulation: 
입력 이미지 Im r R^h×w×3이 주어지면, 우리의 목표는 각 픽셀 값이 왼쪽→오른쪽 또는 위쪽→아래쪽에서 픽셀의 절대 좌표를 정의하는 기울기와 같은 위치 정보 마스크 f_p^ < R^h×w를 예측하는 것이다. 우리는 실험에서 감독을 위해 기본 CNN 아키타입의 가중치가 고정되는 그라데이션과 같은 마스크 Gpos ≤ R^h×w (2.2항)를 생성한다.

### 2.1 Position encoding network
PosENet(그림 2 참조)은 feed forward conv. encoder network fenc와 fpem으로 표시되는 단순 위치 인코딩 모듈의 두 가지 핵심 구성 요소로 구성된다. 인코더 네트워크는 더 얕은 계층에서 더 깊은 계층까지 다양한 level의 추상화 feature를 추출한다. 위치 인코딩 모듈은 인코더 네트워크로부터 multi-scale feature를 입력으로 받아 끝의 절대 위치 정보를 예측한다.
![image](https://user-images.githubusercontent.com/40943064/157390042-53054a1c-a1d0-4281-b7fd-89fb3532c1f5.png)

#### Encoder: 
ResNet 및 VGG 기반 아키텍처를 사용하여 평균 풀링 레이어와 category를 할당하는 레이어를 다시 이동하여 인코더 네트워크(fenc)를 구축한다. 그림 2에 표시된 것처럼 인코더 모듈은 (fθ1, fθ2, fθ3, fθ4, fθ5)로 표시된 5개의 feature extract 블록으로 구성된다. 표준 네트워크의 하단에서 상단으로 이어지는 canonical multi-scale feature는 (fpos1, fpos2, fpos3, fpos4, fpos5)로 표시된다. 주요 작업을 다음과 같이 요약한다.  
f^i_pos =f^i_ps(WaIm)(1). 
인코딩 네트워크를 탐색할 때 위치 인코딩 모듈 fpem만 위치 정보 추출에 초점을 맞추도록 학습되고 인코더 네트워크는 기존 가중치를 유지한다.

#### Position Encoding Module: 
위치 인코딩 모듈은 fenc로부터 다중 스케일 형상(fpos1,··,fpos5)을 입력으로 받아 변환 함수 Tpos를 통해 원하는 위치 맵 fp를 생성한다. 변환 함수 Tpos는 먼저 feature map에 bi-liear interpolation을 적용하여 feature map f^c_pos가 동일한 공간 dimention를 갖도록 한다. 우리가 multi-scale feature에 대해 동일한 spatial dimension 차원을 갖게 되면, 우리는 그것들을 함께 연결한 다음 일련의 k × k conv. 연산을 수행한다. 우리의 실험에서, 우리는 {1, 3, 5, 7} 사이에서 k 값을 변화시키며, 대부분의 실험은 위치 인코딩 모듈 fpem에서 단일 conv. 레이어로 수행된다. 주요 작업은 다음과 같이 요약할 수 있다.  
f^c_pos =(f1_pos ⊕··f5_pos ) f_po=(Wc_pos ∗fc_pos ) (2) 
(W^c_pos : 변환 함수 Tpos에 부착된 학습 가능한 weight). 
인코딩 모듈의 주요 목적은 범주형 레이블에 대해 학습할 때 위치 정보가 암묵적으로 학습되는지 여부를 확인하는 것이다. 또한 위치 인코딩 모듈은 숨겨진 위치 정보와 지상 진리 마스크와 같은 기울기 사이의 관계를 모델링한다. feature map에 인코딩된 위치 정보가 없는 경우 출력은 무작위일 것으로 예상되며 그 반대의 경우도 마찬가지이다.  

### 2.2 Synthetic data and ground-trouth generation
네트워크에서 위치 정보의 존재를 검증하기 위해, 우리는 정규화된 기울기와 같은 1 위치 맵을 그림 3에 표시된 실측 자료로 할당하여 무작위화 테스트를 구현한다. 먼저 수평(H) 및 수직(V) 방향으로 그라데이션과 같은 마스크를 생성한다. 마찬가지로, 우리는 가우스 필터를 적용하여 다른 유형의 지상 진리 지도인 가우스 분포(G)를 설계한다. 이 세 가지 패턴을 생성하는 주요 동기는 모델이 하나 또는 두 개의 축에서 절대 위치를 학습할 수 있는지 검증하는 것이다. 또한 수평 및 수직 스트라이프(HS, VS)라는 두 가지 유형의 반복 패턴을 만듭니다. 방향에 관계없이 다단계 기능의 위치 정보는 인코딩 모듈 fpem에 의한 변환을 통해 모델링될 가능성이 높다. 우리의 그레이디언트 실측 자료 설계는 위치에 대한 입력 이미지와 실측 자료 사이에 상관관계가 없기 때문에 무작위 라벨의 한 유형으로 간주될 수 있다. 위치 정보의 추출은 이미지의 내용과 무관하기 때문에, 우리는 모든 이미지 데이터 세트를 선택할 수 있다. 한편, 우리는 또한 가설을 검증하기 위해 합성 이미지를 구축한다.

### 2.3 Training the network
우리가 암묵적으로 사전 훈련된 네트워크로부터 위치 정보를 인코딩하는 것을 목표로 함에 따라, 모든실험에서 fenc를 고정한다. 우리의 위치 인코딩 모듈 fpem은 관심 있는 position map f^p를 생성한다. 학습 중에, 주어진 입력 이미지 Im ^ R^h×w×3 및 관련 pm ground-truth position map G^h_pos에 대해, 우리는 G^h_pos의 크기로 샘플을 업샘플링하여 f_p f에 supervisory 신호를 적용한다. 그런 다음 다음과 같이 픽셀 단위 평균 제곱 오차 손실을 정의하여 예측 및 실제 지상 위치 맵 간의 차이를 측정한다.
eq3
(x < Rn과 y < Rn (n은 공간 분해능을 나타낸다)은 각각 벡터화된 예측 위치 및 ground-truth map이다. xi와 yi는 각각 f_p and와 G^h_pos의 픽셀을 의미한다.

## 3. Experiments
### 3.1 Dataset and evaluation metrics
**Datasets:** 
우리는 훈련을 위해 10, 533개의 이미지를 포함하는 DUT-S 데이터 세트(Wang 등, 2017)를 훈련 세트로 사용한다. (Zhang 등, 2017; Liu 등, 2018)에서 사용된 공통 훈련 프로토콜에 따라 DUT-S의 훈련 세트에서 모델을 훈련하고 PASCAL-S(Li 등, 2014) 데이터 세트의 자연 이미지에 대한 위치 정보의 존재를 평가한다. 합성 이미지(흰색, 검은색 및 가우스 노이즈)도 섹션 2.2에 설명된 대로 사용됩니다. 훈련과 테스트 세트 사이에 겹치지 않도록 하기 위해 우리는 돌출성 탐지에 사용되는 일반적인 설정을 따른다. 그러나 위치 정보가 비교적 콘텐츠에 독립적이라는 점을 고려할 때 어떤 이미지라도 실험에 사용될 수 있다.

**Evaluation Metrics:**
위치 인코딩 측정은 새로운 방향이기 때문에 범용 메트릭은 없습니다. 우리는 위치 인코딩 성능을 측정하기 위해 지표에 대해 두 가지 다른 자연 선택(SPC)과 MAE(Mean Absoute Error)을 사용한다. SPC는 지상 실측과 예측 위치도 사이의 스피어맨의 상관관계로 정의된다. 해석의 편의를 위해 SPC 점수를 [-1 1] 범위로 유지합니다. MAE는 예측 위치 맵과 지상 진리 기울기 위치 맵 사이의 평균 픽셀 단위 차이이다.

### 3.2 Implementation details
ImageNet 분류 작업을 위해 사전 훈련된 네트워크로 아키텍처를 초기화한다. 위치 인코딩 분기의 새로운 계층은 xavier 초기화를 통해 초기화된다(Glorot & Bengio, 2010). 우리는 0.9의 운동량과 1e-4의 체중 감소로 15세기 동안 확률적 경사 강하를 사용하여 네트워크를 훈련한다. 우리는 훈련과 추론 중에 각 이미지의 크기를 224x224의 고정된 크기로 조정한다. 다단계 피쳐의 공간 범위가 다르기 때문에 모든 피쳐 맵을 28 x 28 크기로 정렬한다. 우리는 다음과 같이 설명된 기준선에 대한 실험 결과를 보고한다: VGG는 Pos를 나타낸다.ENet은 VGG16 모델에서 추출한 기능을 기반으로 합니다. 마찬가지로 ResNet은 ResNet-152와 PosENet의 조합을 나타냅니다. PosENet만 Pos를 나타냅니다.입력 이미지에서 직접 위치 정보를 학습하기 위해 ENet 모델을 적용했습니다. H, V, G, HS 및 VS는 각각 5가지 다른 지상 진실 패턴, 수평 및 수직 그레이디언트, 2D 가우스 분포, 수평 및 수직 스트라이프를 나타낸다.

### 3.3 Existence of position information
사전 학습된 모델의 위치 정보: 

우리는 먼저 사전 훈련된 모델로 인코딩된 위치 정보의 존재를 검증하기 위한 실험을 수행한다. 동일한 프로토콜을 따라 각 유형의 실측 정보를 기반으로 VGG 및 ResNet 기반 네트워크를 교육하고 실험 결과를 표 1에 보고한다. 우리도 포스만 교육했을 때 결과를 보고한다.위치 정보가 객체에 대한 사전 지식으로부터 구동되지 않음을 정당화하기 위해 사전 훈련된 모델을 사용하지 않는 ENet. 우리의 실험은 메트릭에서 더 높은 성능을 달성하는 데 초점을 맞추지 않고 대신 CNN 모델이 인코딩하는 위치 정보의 양 또는 Pos를 얼마나 쉽게 검증한다.ENet은 이 정보를 추출할 수 있습니다. 참고로, 우리는 Pos에 패딩 없이 커널 크기가 3 x 3인 하나의 컨볼루션 레이어만 사용한다.이 실험을 위한 ENet.
표 1과 같이 PosENet(VGG 및 ResNet)은 사전 훈련된 CNN 모델, 특히 ResNet 기반 Pos에서 위치 정보를 쉽게 추출할 수 있다.ENet 모델. 하지만, 훈련 포스이넷
(PosENet)은 다른 패턴과 소스 이미지에서 별도로 훨씬 낮은 점수를 획득한다. 이 결과는 입력 영상에서만 위치 정보를 추출하는 것이 매우 어렵다는 것을 의미한다. PosENet은 심층 인코더 네트워크와 결합된 경우에만 지상 실측 위치 맵과 일치하는 위치 정보를 추출할 수 있다. 앞서 언급한 바와 같이 입력과의 상관관계가 무시된 경우 생성된 지상 진리 지도는 무작위화 테스트의 한 유형으로 간주할 수 있다(Zhang 등, 2016). 그럼에도 불구하고 다양한 실제 패턴에 걸친 테스트 세트의 높은 성능은 모델이 무작정 소음에 과적합되지 않고 대신 실제 위치 정보를 추출한다는 것을 보여준다. 그러나 모델 복잡성과 특히 지상 진실과 절대 위치(표 1의 마지막 두 행) 사이의 상관관계가 부족하기 때문에 다른 패턴에 비해 반복 패턴(HS 및 VS)에서 성능이 낮다. H 패턴은 사인파의 1/4로 볼 수 있는 반면, 줄무늬 패턴(HS 및 VS)은 사인파의 반복적인 기간으로 간주되어 더 깊은 이해가 필요하다.

다양한 패턴에 걸친 여러 아키텍처에 대한 정성적 결과는 그림 4에 나와 있다. 우리는 H, G 및 HS 패턴에 해당하는 예측된 진실 위치 맵과 지상 진실 위치 맵 사이의 상관관계를 볼 수 있으며, 이는 이러한 네트워크에서 위치 정보의 존재를 더욱 드러낸다. 양적 및 질적 결과는 위치 정보가 이 목표에 대한 명시적 감독 없이 모든 아키텍처에 암묵적으로 인코딩된다는 가설을 강하게 검증한다.

또한 PosENet만으로는 합성 데이터를 기반으로 한 그라데이션 맵을 출력할 수 있는 용량이 없다. 우리는 4.1항에서 이미지 의미론의 효과를 추가로 탐구한다. ResNet 기반 모델이 VGG16 기반 모델보다 더 높은 성능을 달성하는 등 아키텍처 간 성능 차이가 크다는 점이 흥미롭다. 그 이유는 아키텍처에서 다른 컨볼루션 커널을 사용하거나 의미론적 내용에 대한 사전 지식의 정도 때문일 수 있다. 추가 조사를 위해 다음 실험에서 절제 연구를 보여준다. 이 논문의 나머지 부분에서는 자연 이미지, PASCAL-S 데이터 세트 및 세 가지 대표적인 패턴인 H, G 및 HS에만 초점을 맞춘다.
### 3.4 Analysing posnet
이 섹션에서는 두 가지 주요 설계 선택을 강조하여 제안된 위치 인코딩 네트워크의 역할을 조사하기 위한 절제 연구를 수행한다. (1) 위치 인코딩 모듈에서 다양한 커널 크기의 역할과 (2) 다중 수준 특징에서 위치 정보를 추출하기 위해 추가하는 컨볼루션 레이어의 스택 길이.

#### Impact of Stacked Layers:
표 1의 실험 결과는 객체 분류 작업에서 학습한 위치 정보의 존재를 보여준다. 이 실험에서 우리는 Pos의 디자인을 변경한다.ENet 은닉 위치 정보를 더 정확하게 추출할 수 있는지 검사합니다. 포스이전 실험(표 1)에 사용된 ENet은 커널 크기가 3 × 3인 컨볼루션 레이어 하나만 가지고 있다. 여기서는 길이가 다양한 컨볼루션 레이어 스택을 Pos에 적용한다.ENet 및 표 2 (a)에 해당 결과를 보고한다. 스택 크기는 다양하지만 상대적으로 단순한 Pos를 유지하는 것을 목표로 한다.ENet 위치 정보를 효율적으로 읽을 수만 있습니다. 표 2와 같이, 우리는 여러 개의 레이어를 쌓는 동안 커널 크기를 3 x 3으로 고정시킵니다. Pos에 더 많은 레이어 적용ENet은 모든 네트워크에 대한 위치 정보 읽기를 개선할 수 있습니다. 한 가지 이유는 다중 컨볼루션 필터를 쌓으면 네트워크가 더 큰 효과적인 수용 필드를 가질 수 있기 때문이다. 예를 들어 두 개의 3 × 3 컨볼루션 레이어는 공간적으로 하나의 5 × 5 컨볼루션 레이어와 동일하다(Simonyan & Zisserman, 2014). 대안적인 가능성은 위치 정보가 1차 추론(예: 선형 판독값) 이상을 요구하는 방식으로 표현될 수 있다는 것이다.

#### Impact of varing Kernel Sizes:
Pos를 추가로 검증합니다.다른 커널 크기를 가진 하나의 컨볼루션 레이어만을 사용하여 ENet을 수행하고 실험 결과를 표 2 (b)에 보고한다. 표 2 (b)에서, 더 큰 커널 크기는 더 작은 크기에 비해 더 많은 위치 정보를 캡처할 수 있다는 것을 알 수 있다. 이 발견은 더 큰 수용 필드가 위치 정보를 더 잘 해결할 수 있기 때문에 위치 정보가 계층 내 및 특징 공간에서 공간적으로 배포될 수 있음을 의미한다.

또한 그림 5에서 위치 정보를 학습하기 위해 다양한 계층 수와 커널 크기의 시각적 영향을 보여준다.

### 3.5 Where is the position information stored?
우리의 이전 실험은 위치 정보가 사전 훈련된 CNN 모델로 인코딩된다는 것을 보여준다. 위치정보가 계층 전체에 균등하게 분포돼 있는지도 관심사다. 이 실험에서 우리는 포스를 훈련시킨다.VGG16을 사용하여 추출된 각 특징 fp1os, fp2os, fp3os, fp4os, fp5os에 대한 ENet을 별도로 사용하여 어느 레이어가 더 많은 위치 정보를 인코딩하는지 조사합니다. 3.3절과 유사하게, 우리는 위치 맵을 얻기 위해 Fpem에 하나의 3 × 3 커널만 적용한다.

표 3과 같이 VGG 기반 Pos상위 fp5os 기능이 있는 ENet은 하위 fp1os 기능에 비해 더 높은 성능을 달성합니다. 이것은 부분적으로 더 많은 피쳐 맵의 결과일 수 있다.
각각 512 x 64의 얕은 층이 아닌 더 깊은 층으로부터 착지된다. 그러나, 그것은 높은 수준의 의미론에 의해 정보가 공유되는 네트워크의 가장 깊은 계층에서 위치 정보의 더 강력한 인코딩을 나타낼 가능성이 있다. 우리는 상위 두 계층(fp4os 및 fp5os)이 동일한 수의 특징을 갖는 VGG16에 대해 이 효과를 추가로 조사한다. 더 정확히 말하자면, fp5os는 fp4os보다 더 나은 결과를 얻는다. 이 비교는 더 깊은 특징에는 더 많은 위치 정보가 포함되어 있음을 시사하며, 이는 최상위 수준의 시각적 특징이 전역 특징과 연관되어 있다는 일반적인 믿음을 입증한다.

## 4. Where does position information come from?
Border 근처의 패딩은 배울 수 있는 위치 정보를 전달한다고 생각합니다. 제로 패딩은 입력과 출력에 대해 동일한 공간 치수를 유지하기 위해 컨볼루션 레이어에서 널리 사용되며, 수평과 수직 두 축의 시작과 끝에 많은 0이 추가된다. 이를 검증하기 위해 VGG16 내에 구현된 모든 패딩 메커니즘을 제거하지만 ImageNet 사전 훈련된 가중치로 모델을 초기화한다. VGG 기반 Pos를 사용해서만 이 실험을 수행한다는 점에 유의하십시오.ResNet 모델에서 패딩을 제거하면 스킵 연결의 크기가 일정하지 않게 되므로 ENet. 먼저 PosENet에 사용된 패딩이 아닌 VGG에 사용된 제로 패딩의 효과를 테스트한다. 표 4에서 볼 수 있듯이 제로 패리티가 없는 VGG16 모델은 자연 이미지의 기본 설정(default=1)보다 훨씬 낮은 천공을 달성한다. 마찬가지로, 우리는 Pos에 위치 정보를 소개한다.제로 패딩을 적용하여 ENet. 패딩=1이 있는 PosENet(프레임 주위에 0이 하나 있음)은 원본(pading=0)보다 더 높은 성능을 달성합니다. 패딩=2로 설정하면 위치 정보의 역할이 더 명확해집니다. 이것은 또한 Pos를 보여주는 3.3절의 우리의 실험을 검증한다.ENet은 패딩이 적용되지 않았기 때문에 눈에 띄는 위치 정보를 추출할 수 없으며, 정보는 사전 훈련된 CNN 모델에서 인코딩된다. d이것이 우리가 Pos에서 제로 패딩을 적용하지 않은 이유이다.이전 실험에서 ENet. 또한, 우리는 PosENet과 직접 결합하는 대신 얼마나 많은 위치 정보가 사전 훈련된 모델에 인코딩되는지 탐색하는 것을 목표로 한다. 그림 6은 제로 패딩이 가우스 패턴을 사용하여 패딩 대상 위치 정보 인코딩에 미치는 영향을 보여준다.

### 4.1 Case study
위치 정보는 내용과 무관한 것으로 간주되지만 Table 1의 결과는 이미지 내의 semantics는 position map에 영향을 미칠 수 있음을 보여준다. semantics의 영향을 시각화하기 위해 다음 방정식을 사용하여 콘텐츠 손실 heat map을 계산한다.

Eq.4

그림 7과 같이 Pos의 히트맵은ENet은 코너별로 콘텐츠 손실이 더 크다. 반면 VGG와 ResNet의 손실 맵은 의미론적 콘텐츠와 더 관련이 있다. 특히 ResNet의 경우 의미론적 콘텐츠에 대한 이해가 깊어질수록 부드러운 그레이디언트를 생성하는 데 더 강한 간섭이 발생한다. 가장 큰 손실은 얼굴, 사람, 고양이, 비행기, 꽃병(왼쪽에서 오른쪽으로)이다. 이 시각화는 모델이 특히 ResNet의 경우 어떤 영역에 초점을 맞추고 있는지를 보여주는 대체 방법이 될 수 있다.

### 4.2 Zero-padding driven position information
#### Saliency Detection:
우리는 위치 의존적 작업(의미적 분할 및 두드러진 객체 감지(SOD))에서 우리의 발견을 추가로 검증한다. 첫째, 제로 패딩을 사용하거나 사용하지 않는 VGG 네트워크를 교육하여 제로 패딩을 통해 전달되는 위치 정보가 두드러진 영역을 감지하는 데 중요한지 검증한다. 이러한 실험을 위해 공개적으로 사용 가능한 MSRA 데이터 세트(Cheng 등, 2015)를 SOD 교육 세트로 사용하고 세 가지 다른 데이터 세트(ECSSD, PASCAL-S 및 DUT-OMRON)에 대해 평가한다. 표 5 (a)에서 패딩이 없는 VGG는 두 메트릭(F-measure 및 MAE) 모두에서 훨씬 나쁜 결과를 달성하여 제로 패딩이 위치 정보의 핵심 소스라는 우리의 발견을 더욱 검증할 수 있다.

**Semantic Segmentaion:** 
우리는 또한 제로 패딩이 의미 분할 작업에 미치는 영향을 검증한다. PASCAL VOC 2012 데이터 세트의 교육 세트에서 패딩이 0인 VGG16 네트워크를 교육하고 검증 세트에서 평가한다. SOD와 마찬가지로 패딩이 0인 모델은 패딩이 없는 모델보다 성능이 훨씬 뛰어나다.

우리는 이 두 가지 작업에 대해 사전 훈련된 CNN 모델이 분류 작업보다 더 많은 위치 정보를 학습할 수 있다고 믿는다. 이 가설을 검증하기 위해 ImageNet에서 사전 훈련된 VGG 모델을 기준으로 한다. 한편, 우리는 처음부터 VGG-SS 및 VGG-SOD로 표시되는 의미 분할 및 돌출성 검출 작업에 대한 두 가지 VGG 모델을 교육한다. 그런 다음 섹션 3.3에 사용된 프로토콜을 따라 이 세 가지 VGG 모델을 미세 조정한다. 표 6에서 VGG-SS 및 VGG-SOD 모델이 VGG를 큰 폭으로 능가한다는 것을 알 수 있다. 이러한 실험은 제로 패딩 전략이 위치 의존적 작업에서 중요한 역할을 한다는 것을 보여주는데, 이는 시각 문제에 대한 신경망 솔루션에서 오랫동안 무시되어 온 관찰이다.

## 5. Conclusion
이 논문에서 우리는 절대 위치 정보가 컨볼루션 신경망에 암묵적으로 인코딩된다는 가설을 탐구한다. 실험 결과 위치 정보가 상당히 이용 가능하다는 것이 밝혀졌다. 보다 상세한 실험에 따르면 더 큰 수용장 또는 위치 정보의 비선형 판독은 사소한 단일 레이어 3 × 3 PosENet에서 이미 매우 강한 절대 위치의 판독을 더욱 증가시킨다. 실험은 또한 의미 단서가 없고 의미 정보의 간섭이 무엇(의미적 특징)과 어디에(절대적 위치)의 공동 인코딩을 제안할 때 이러한 복구가 가능하다는 것을 보여준다. 결과는 공간 추상화가 발생할 때 position information이 파생되고 결국 전체 이미지에 전파되는 앵커로 패딩과 경계를 제로(zero)로 가리킨다. 이러한 결과는 현재까지 알려지지 않은 CNN의 기본 특성을 보여주며, 이에 대해 훨씬 더 많은 연구가 필요하다.
