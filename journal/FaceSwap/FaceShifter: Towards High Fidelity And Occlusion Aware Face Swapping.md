# FaceShifter: Towards High Fidelity And Occlusion Aware Face Swapping

## Abstract
FaceShifter는 높은 충실도와 함께 occlusion을 고려하여 face swapping 하는 두 단계로 구성된 framework이다. Swap된 얼굴을 합성할 때 target 이미지로부터 제한된 정보만을 이용하는 여러 face swapping 방식과는 달리 target attribute를 이용하고 통합하여 완전히 적응적으로 충실도 높은 swapped face를 생성한다.  
다음 두가지를 제안한다.  
1) Multi-level의 target 얼굴 attribute를 추출하기 위한 새로운 attribute encoder
2) 얼굴 합성을 위한 ID와 attribute를 적응적으로 통합하기 위해 신중하게 설계된 AAD(Adaptive Attentional Denormalization) 레이어가 있는 새로운 G  

까다로운 얼굴의 occlusion을 다루기 위해 두단계를 구성하는 새로운 Heuristic Error Acknowledging Refinement Network (HEAR-Net)을 추가한다. Annotation 없이 self-supervised 방식으로 이상 영역을 복구하도록 학습한다. Wild face에 대한 광범위한 실험은 우리의 얼굴 교환 결과가 SOTA와 비교하여 훨씬 더 지각적으로 매력적일 뿐만 아니라 더 나은 ID 보존을 보여준다.  

## 1. Introduction
Faceswap 설명 > Faceswap의 활용 > Faceswap 기술에서 어려운 점 > 

1) 초기 replacement 기반 작업 : 얼굴 내부 픽셀만 대체하므로 pose와 perspective 변화에 민감함   
2) 3D 기반 작업 : pose/perspective 차이를 다루기 위해 3D 모델 사용 했지만 3D reconstruction의 정확성과 견고성은 모두 부족
3) GAN 기반 작업 : 성능은 상대적으로 향상되었으나 현실적인 결과와 높은 충실도의 결과를 모두 합성하는 것은 여전히 어려움  
본저는 결과의 충실도 향상에 데 중점을 둔다. 지각적으로 매력적으로 만들기 위해서 합성얼굴이 대상 얼굴의 **포즈와 표정**을 공유할 뿐만 아니라 촘촘하게 대상 이미지에 원활하게 맞아야 한다. 렌더링은 target scence의 조명(방향, 강도, 색상)에 충실해야 하며, 픽셀 해상도는 대상 이미지 해상도와 일치해야 한다. 이 두 가지 모두 단순한 알파 또는 포아송 혼합으로는 잘 처리되지 않는다. 대신, scene 조명 또는 이미지 해상도를 포함한 대상 이미지의 속성이 스왑된 얼굴을 보다 사실적으로 만드는 데 도움이 될 수 있도록 스왑된 얼굴의 합성 중에 대상 이미지 속성의 철저하고 적응적인 통합이 필요하다. 그러나 이전의 얼굴 교환 방법은 이 통합의 요구 사항을 무시하거나 철저하고 적응적인 방식으로 수행할 수 있는 능력이 부족하다.  

(FSGAN) 기존의 방법들은 대상 이미지의 포즈 및 표현 지침만 사용하여 스왑된 얼굴을 합성하고, 이후 대상 얼굴의 마스크를 사용하여 대상 이미지에 얼굴을 혼합한다. 이 프로세스는 아래 이유로 아티팩트를 일으키기 쉽다.  
1) 자세/표정 외에도, 장면 조명이나 이미지 해상도와 같은 목표 속성을 거의 존중할 수 없는, 스왑된 얼굴을 합성할 때 대상 이미지에 대한 지식을 거의 활용하지 않는다.  
2) 이러한 혼합은 해당 위치의 소스 면의 모든 주변 영역을 버립니다.대상 안면 마스크 외부에 있는 테. 따라서 이러한 방법은 소스 ID의 얼굴 모양을 보존할 수 없다. 그림 2에 몇 가지 일반적인 실패 사례를 보여 줍니다. 높은 충실도의 얼굴 교환 결과를 달성하기 위해, 프레임워크의 첫 번째 단계에서는 대상 속성의 철저하고 적응적인 통합을 위해 적응형 임베딩 통합 네트워크(AEI-Net)라는 GAN 기반 네트워크를 설계한다. 우리는 네트워크 구조에 두 가지 개선을 했다. 1) RSGAN [29]과 IPGAN [5]로 단일 벡터로 압축하는 대신 다양한 공간 해상도에서 대상 속성을 추출하기 위한 새로운 다단계 속성 인코더를 제안한다. 2) 우리는 속성이나 아이덴티티 임베딩을 통합할 위치를 적응적으로 학습하는 신중하게 설계된 적응형 주의 변칙화(AAD) 레이어를 가진 새로운 생성기를 제시한다. 이러한 적응형 통합은 RSGAN [29], FSNet [28] 및 IPGAN [5]에서 사용하는 단일 수준 통합보다 상당한 개선을 가져온다. 이 두 가지 개선점을 통해 제안된 AEI-Net은 그림 2와 같이 조도와 얼굴 모양이 일정하지 않은 문제를 해결할 수 있다. 또한 얼굴 교환에서 얼굴 폐색을 처리하는 것은 항상 어렵다. Nirkin 등과는 다릅니다. 폐색 인식 안면 마스크를 얻기 위해 얼굴 분할을 훈련하는 [30, 31] 우리의 방법은 수동 주석 없이 얼굴 이상 영역을 자체 분석 방식으로 복구하는 방법을 배울 수 있다. 우리는 잘 훈련된 AEI-Net에 대상 및 소스와 동일한 얼굴 이미지를 제공할 때 재구성된 얼굴 이미지가 여러 영역의 입력에서 벗어난다는 것을 관찰한다. 이러한 편차는 얼굴 폐색 위치를 강하게 암시한다. 따라서, 우리는 그러한 재구성 오류의 안내에 따라 결과를 더욱 세분화하기 위해 새로운 휴리스틱 오류 인식 정제 네트워크(HEAR-Net)를 제안한다. 제안된 방법은 더 일반적이므로 안경, 그림자 및 반사 효과, 기타 흔치 않은 폐색 등과 같은 더 많은 이상 유형을 식별한다. 제안된 2단계 얼굴 교환 프레임워크인 FaceShifter는 주제에 구애받지 않는다. 일단 훈련되면, 이 모델은 딥페이크[1]와 코르슈노바 등과 같은 과목별 훈련 없이 새로운 얼굴 쌍에 적용될 수 있다. [22] 실험은 우리의 방법이 다른 최첨단 방법보다 훨씬 더 현실적이고 입력에 충실한 결과를 달성한다는 것을 보여준다.
