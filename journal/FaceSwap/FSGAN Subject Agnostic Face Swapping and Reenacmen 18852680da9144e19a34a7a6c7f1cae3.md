# FSGAN: Subject Agnostic Face Swapping and Reenacment

Created: 2022ë…„ 1ì›” 2ì¼ ì˜¤í›„ 8:05
Property: 2022ë…„ 1ì›” 3ì¼
Property 1: ì´ê·œì² 
Tags: 3Dface, Synthesis, face reenactment, face swap

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled.png)

[https://www.youtube.com/watch?v=BsITEVX6hkE&feature=emb_title](https://www.youtube.com/watch?v=BsITEVX6hkE&feature=emb_title)

## Abstract

---

**Functional Novelty**

1. **Reenactment â†’** **Swapping** ìˆœì„œë¡œ pipelineì„ êµ¬ì„±í•˜ì—¬ ë‘ ê°€ì§€ task ëª¨ë‘ ê°€ëŠ¥
2. íŠ¹ì • ì–¼êµ´ì— ëŒ€í•´ í•™ìŠµ ì—†ì´ ì„ì˜ ì–¼êµ´ì— ëŒ€í•´ **Swapping** ê°€ëŠ¥

### **Methodological Novelty**

1. **Video Sequences ì‚¬ìš© ì‹œ interpolation**(**reenactment, Delaunay triangulation, ë¬´ê²Œì¤‘ì‹¬**)ì„ í†µí•´  ****ë” ë‚˜ì€ ê²°ê³¼ íšë“
2. RNN í™œìš© **ë‹¨ì¼ ì´ë¯¸ì§€ í˜¹ì€ ë‹¨ì¼ ë¹„ë””ì˜¤ sequence**ì— ëŒ€í•œ Reenactment(**ìì„¸, í‘œì •)**
(landmark í•„ìš”)
3. face completion network(in-paint network)ë¥¼ í†µí•´ Occluded ì˜ì—­  ì²˜ë¦¬
4. ì–¼êµ´ ìƒ‰ìƒì´ë‚˜ ì¡°ëª… ì¡°ê±´ì„ ë³´ì¡´í•˜ê¸° ìœ„í•´ Perceptual lossì— Poisson blending loss(Poisson optimization)ë¥¼  ì¶”ê°€í•œ blending network í™œìš©

**Keyword : RNN using reenactment, interpolation, in-painting NN, Poisson blending**

## 1. Introduction

---

### 1) 3D ëª¨ë¸ì„ í™œìš©í•œ ë°©ë²•

ë‹¨ì  **: Occluded region ì²˜ë¦¬ ì‹œ íŠ¹ë³„í•œ ì²˜ë¦¬ê°€ í•„ìš”í•¨**

- (CVPR2016) Face2Face: real-time face capture and reenactment of rgb videos

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%201.png)

- (TOG2017) Synthesizing obama: learning lip sync from audio
- (FG 2018) On face segmentation, face swapping, and face perception
: 2D facial landmark detection â†’ 3D fitting(pose+expression) â†’segmentation â†’ blending

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%202.png)

### 2) GANì„ í™œìš©í•œ ë°©ë²•

: cGAN(pix2pix) ì•„ì´ë””ì–´ í™œìš©

- (ECCV2018) Ganimation: Anatomically-aware facial animation from a single image
- Triple consistency loss for pairing distributions in gan-based face synthesis

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%203.png)

- (ECCV2018) Reenactgan: Learning to reenact faces via boundary transfer

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%204.png)

<aside>
ğŸ’¡ ë¶„ì•¼ í™•ì¥ì— í° ê¸°ì—¬ë¥¼ í•œ DeepFake ë„ cGANê³¼ 3D ëª¨ë¸ì„ í™œìš©í•œ ë°©ë²•ì„

</aside>

### 3) Latent feature ë¶„ë¦¬ ë°©ë²•

**ë‹¨ì  : ID ì •ë³´ ë¶„ë¦¬ì‹œ ì¤‘ìš” ì •ë³´ê°€ ì†ì‹¤ë˜ì–´ í•©ì„± ì´ë¯¸ì§€ í’ˆì§ˆì´ ì €í•˜**

- (ACCV2018) Fsnet: An identity-aware generative model for image-based face swapping

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%205.png)

- Rsgan: face swapping and editing using face and hair representation in latent spaces

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%206.png)

- Cr-gan: learning complete representations for multi-view generation
: Z spaceë¥¼ ì „ì²´ í•™ìŠµí•˜ë„ë¡ í•˜ì—¬ complete representationsì„ ë§Œë“¤ë©´ ë³´ì§€ëª»í•œ ì…ë ¥ì—ë„ ì´ë¯¸ì§€ ìƒì„± ê°€ëŠ¥

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%207.png)

<aside>
ğŸ’¡ ì•ì„œ ì†Œê°œë˜ì—ˆë˜ Synthesizing obama, DeepFake, Deep video portraits, Reenactgan ë°©ë²• ëª¨ë‘ Subject specific ë°©ë²•ë¡ 

</aside>

### ê¸°ì¡´ ë°©ë²•ë¡ ì˜ ë‹¨ì 

1) Subject specific

2) 3D ëª¨ë¸ í™œìš©ì‹œ occluded ì²˜ë¦¬ ë°©ë²• í•„ìš”

2) Latent ë¶„ë¦¬ë¡œ ì¸í•œ ì´ë¯¸ì§€ í’ˆì§ˆì €í•˜

## 3. Face swapping GAN

---

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%208.png)

### 1) ë¬¸ì œ ì •ì˜

**ì£¼ì–´ì§„ ì´ë¯¸ì§€ ì„¸íŠ¸ì— ëŒ€í•´**

Fs(Source faces) âˆˆ Is(Source images)

Ft(Target faces)âˆˆ It(Target images)

**Target image ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìì„¸ì™€ í‘œì •ì„ ìœ ì§€í•˜ë©´ì„œ Â Ftê°€Â  Fsì— ì˜í•´ ëŒ€ì²´ë˜ë„ë¡ í•¨**

### 2) **FSGAN pipelineì˜ 3ê°€ì§€ êµ¬ì„± ìš”ì†Œ**

**1-1. Reenactment Gr**

: Ftì˜ (ìì„¸ì™€ í‘œì •)ê³¼ ì¼ì¹˜í•˜ë„ë¡ í•˜ë©°  : Frì´ Fsë¥¼ ëª¨ì‚¬í•˜ë„ë¡ reenact ëœ ì´ë¯¸ì§€ Irì„ ìƒì„± : Frì˜ SegmentationÂ  Sr ìƒì„±

**1-2. Segmentation Gs**

1-1. ê²°ê³¼ì— target image ê°€ì´ë“œë¼ì¸ì„ ì£¼ê¸° ìœ„í•´ Ftì— ëŒ€í•œ ì–¼êµ´ê³¼ í—¤ì–´ segmentation ìƒì„±  

**2.  Inpainting Gc** IrëŠ” source IDì˜ occlusionì— ì˜í–¥ ë°›ì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì´ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ in-painting network ì‚¬ìš©

ì…ë ¥ìœ¼ë¡œ Ir~ì™€ Stë¥¼ ì‚¬ìš©

**3. Blending Gb**

ì™„ì„±ëœ ì–¼êµ´ì´ë¯¸ì§€ Fcë¥¼ Itì—Â  ì…í˜

### 3) ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°

**Gs** : U-net + biliear interpolation upsampling

**Gr**, **Gc** , **Gb** : Pix2PixHD(coarse-to-fine G and multi-scale D) + U-net + concat(not sum)
+ biliear interpolation upsampling(segmentation ê³¼ ë™ì¼í•œ upsampling ë°©ì‹ ì ìš©)

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%209.png)

(pix2pixHDì˜ Generator network êµ¬ì¡°)

### 4) Etc.

- **Subject agnostic** ë°©ì‹ì´ë¯€ë¡œ pose ì°¨ì´ê°€ í° ê²½ìš° ë³€í™˜ì´ ì‹¤íŒ¨í•˜ê¸° ì‰¬ì›€. ì´ë¥¼ ìœ„í•œ í•´ê²°ì±…ìœ¼ë¡œ ë‘ê°€ì§€ ë°©ë²•ì„ ì‚¬ìš©
1) í° poseì˜ ì°¨ì´ë¥¼ ì—¬ëŸ¬ ë³€í™˜ ë‹¨ê³„ë¡œ ë¶„í• 
2) target poseì— ê°€ì¥ ê°€ê¹Œìš´ sourceë¥¼ ì°¾ì•„ interpolation

### 3.1. Training losses

- **Domain specific perceptual loss.**

:  VGGì˜ layerë³„ feature ê°’ìœ¼ë¡œ(layer 1~n) **high-frequency detail**ì„ ë¹„êµí•˜ê¸° ìœ„í•´ í™œìš©
: ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë˜ë©° ì–¼êµ´í•©ì„±ì—ì„œë„ ë¹ˆë²ˆí•˜ê²Œ ì‚¬ìš©
: ì–¼êµ´ ì´ë¯¸ì§€ì˜ ê³ ìœ ì •ë³´ë¥¼ í¬ì°©í•˜ëŠ”ë° ë¬¸ì œê°€ ìˆì–´ ì‚¬ì „í•™ìŠµëœ ImageNetì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì ìš©í•˜ëŠ” ë„ë©”ì¸ ë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬ ì–¼êµ´ ì¸ì‹ ë° ì†ì„± ë¶„ë¥˜ë¬¸ì œì— í•™ìŠµí•˜ì—¬ í™œìš©

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%2010.png)

- **Reconstruction loss.**

: perceptual lossë§Œ ì‚¬ìš©í•˜ë©´ low-frequency contentì˜ reconstructionì— í•´ë‹¹í•˜ëŠ” ë¶€ì •í™•í•œ ìƒ‰ìƒì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê¸°ì— L1 loss ì‚¬ìš©

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%2011.png)

ë”°ë¼ì„œ ëª¨ë“  **G í•™ìŠµ**ì— ì‚¬ìš©ë˜ëŠ” í†µí•© reconstruction lossëŠ” ì•„ë˜ì™€ ê°™ë‹¤.

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%2012.png)

- **Adversarial loss.**

: ì´ë¯¸ì§€ì˜ ì‚¬ì‹¤ì„± í–¥ìƒ(ì‹¤ì œ ë¶„í¬ ê·¼ì‚¬)ì„ ìœ„í•´ adversarial lossë„ í•¨ê»˜ í™œìš©
: Multi-scale Dë¥¼ í™œìš© ë°˜ì˜
x : Is, y:It

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%2013.png)

<aside>
ğŸ’¡ **Multi-scale D**
ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ì„œëŠ” (ê¹Šì€ layer, í° kernelì„ í†µí•´ receptive)ë¥¼ ë„“í˜€ì•¼ í•œë‹¤. ì´ ê²½ìš° í‘œí˜„ capacityëŠ” ì¦ê°€í•˜ì§€ë§Œ í•´ìƒë„ì— ë¹„í•´ ì‘ì€ ë°ì´í„° ì…‹ì˜ í•œê³„ë¡œ over-fittingì´ ë°œìƒí•  ìˆ˜ ìˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ multi-scale Dë¥¼ ì‚¬ìš©í•˜ê³  ì…ë ¥ìœ¼ë¡œ pyramid image(í•´ìƒë„ë¥¼ 2, 4ì”© ë‚®ì¶˜)ë¥¼ ì‚¬ìš©í•œë‹¤. ë™ì¼ êµ¬ì¡°ì˜ Dì— ëŒ€í•´ ë‹¤ë¥¸ í•´ìƒë„ë¥¼ ì…ë ¥í•˜ì—¬ í•™ìŠµí•˜ëŠ” ê²ƒì´ë‹¤.
(**ref. :** Generative Multi-Adversarial Networks, pix2pixHD)

</aside>

multi-scale Dê°€ ì—†ìœ¼ë©´ ìƒì„±ëœ ì´ë¯¸ì§€ì— ë°˜ë³µë˜ëŠ” íŒ¨í„´ì´ ë§ì´ ë‚˜íƒ€ë‚˜ëŠ” ê²ƒì„ ê´€ì°°í•  ìˆ˜ ìˆë‹¤.

### 3.2. Face reenactment and segmentation

ì‚¬ìš©ë˜ëŠ” ë³€ìˆ˜ì™€ ê·¸ í¬ê¸°ëŠ” ì•„ë˜ì™€ ê°™ìŒ

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%2014.png)

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%2015.png)

ë¨¼ì €, sourceì™€ targetì˜ pose ì°¨ì´ê°€ í° ê²½ìš° í•´ê²°ì±…ìœ¼ë¡œ ì œì‹œí–ˆë˜ **ë¶„í•  ë°©ì‹**ì„ ì„¤ëª…í•œë‹¤.

ì˜¤ì¼ëŸ¬ê° esì™€ et, vsì™€ vtì˜ ë¬´ê²Œì¤‘ì‹¬ ì‚¬ì´ë¥¼ ë³´ê°„í•˜ì—¬ ì¤‘ê°„ 2D ëœë“œë§ˆí¬ ìœ„ì¹˜ pjë¥¼ ìƒì„±í•˜ê³  vsë¥¼ Isë¡œ ë‹¤ì‹œ íˆ¬ì˜í•˜ëŠ” ì¤‘ê°„ ì§€ì ì„ ì‚¬ìš©í•œë‹¤. 

Is â†’ Ir1 â†’ Ir2 â†’ ... (I rn = Ir)

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%2016.png)

ê¸°ì¡´ì— ì‚¬ìš©ë˜ì—ˆë˜ ë°©ë²•ì¸ 0/1 maskì™€ ë‹¬ë¦¬ ì–¼êµ´ê³¼ ë¨¸ë¦¬ì¹´ë½ ì˜ì—­ì„ ì¶”ê°€ë¡œ ê³ ë ¤í•¨ìœ¼ë¡œì¨ ì–¼êµ´ segmentation ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆë‹¤.

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%2017.png)

**Traning.**

ê¸°ì¡´ ì •ì˜í•œ Lrecì— ëŒ€í•œ loss ê³„ì‚° ì…ë ¥ìœ¼ë¡œ rn ë²„ì „ê³¼ r ë²„ì „ ëª¨ë‘ ì‚¬ìš©í•˜ë©° ë¶„í• ì„ í†µí•œ loss ê³„ì‚° termì€ stepwise consistency lossë¼ê³  ì •ì˜í•œë‹¤.

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%2018.png)

Gs ì— ëŒ€í•´ì„œëŠ” ì•„ë˜ì™€ê°™ì´ ì •ì˜ ëœë‹¤.
Srt(Gr(It;H(pt)))ëŠ” sourceì™€ target ë™ì¼ idë¡œ ì£¼ì–´ì§„ ê²½ìš°ë¥¼ íŠ¹ë³„íˆ ì •ì˜í•˜ëŠ” ìƒí™©ì´ë©°

ë™ì¼ í•´ë‹¹ ì´ë¯¸ì§€ì— ëŒ€í•œ Segmentation labelì´ ìˆê¸° ë•Œë¬¸ì— í•™ìŠµ ê°€ëŠ¥í•˜ë‹¤.

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%2019.png)

í•™ìŠµì€ Grê³¼ Gsë¥¼ 1 epochì”© ë²ˆê°ˆì•„ê°€ë©° ìˆ˜í–‰í•˜ë©° ì´ ê²½ìš° ì„±ëŠ¥ì´ ê°€ì¥ ì˜ ë‚˜ì˜¨ë‹¤.

### 3.3. Face view interpolation

ì—°ì†ì ì¸ viewë¥¼ ë§Œë“¤ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë°©ë²•ì„ ì œì‹œí•œë‹¤. 

íŠ¹ì • ë¹„ë””ì˜¤ í”„ë ˆì„ì—ì„œ í•™ìŠµí•˜ì§€ ì•Šê³ ë„ ì „ì²´ ì†ŒìŠ¤ ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ agnosticí•˜ë‹¤.

íŠ¹ì • video sequenceì— ëŒ€í•´ ë‹¤ìŒì˜ ë°ì´í„°ë¥¼ ì •ì˜í•œë‹¤.

ì´ë¯¸ì§€ ì„¸íŠ¸ {Is1, Is2, ..., Isn}, ì˜¤ì¼ëŸ¬ ê°ë„ ì„¸íŠ¸ {es1, es2, ..., esn}, ì–¼êµ´ ì„¸íŠ¸ {Fs1, Fs2, ..., Fsn} 

ì´ë•Œ ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ì´ source videoì— ëŒ€í•´ appearance mapì„ êµ¬ì„±í•œë‹¤. 

(roll angleì€ drop : head poseë¥¼ ì¶”ì •í•˜ëŠ”ë° í¬ê²Œ ì¤‘ìš”í•˜ì§€ ì•Šì€ë“¯)

ì´ë•Œ, ê°€ê¹Œìš´ pointëŠ” ì œê±°í•˜ë©° (roll angleì´ 0ì´ ë˜ëŠ” í¬ì¸íŠ¸ë¥¼ ë‚¨ê¹€) blurry í•œ ì´ë¯¸ì§€ ì œê±°

ë‚¨ì€ í¬ì¸íŠ¸ì— ëŒ€í•´ -75 ~ 75 ì˜ì—­ì—ì„œ ë“¤ë¡œë„¤ ì‚¼ê°í˜•ì„ ì´ìš©í•´ meshë¥¼ êµ¬ì„±

Queryê°€ ë˜ëŠ” et ì…ë ¥ â†’ ê°€ê¹Œìš´ ì‚¼ê°í˜•ì„ íƒìƒ‰ â†’ vertexë¥¼ êµ¬ì„±í•˜ëŠ” 3ê°œì˜ xì— ëŒ€í•œ Is ì¶”ì¶œ â†’ 3ê°œì˜ ë¬´ê²Œì¤‘ì‹¬ìœ¼ë¡œ weight ê³„ì‚° â†’ ì•„ë˜ ìˆ˜ì‹ì„ í†µí•˜ì—¬ ì—°ì‚° í›„ ê²°ê³¼ ì¶”ì¶œ 
(í¬ì¸íŠ¸ xê°€ boundary lineì— ì¡´ì¬í•˜ëŠ” ê²½ìš° í•˜ë‚˜ì˜ í¬ì¸íŠ¸ë¥¼ ì œê±°í•˜ê³  lamdaë¥¼ ë‹¤ì‹œ normalizeí•˜ì—¬ 2ê°œë¡œ ê³„ì‚°)

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%2020.png)

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%2021.png)

### 3.4. Face inpainting

Sourceì— ì¡´ì¬í•˜ëŠ” occlusion ì˜ì—­ì„ ì²˜ë¦¬í•´ì•¼ ì œëŒ€ë¡œ targetì´ë¯¸ì§€ë¥¼ ë³€í™˜í•  ìˆ˜ ìˆë‹¤.

ì €ìì˜ ê³¼ê±° ë°©ì‹ì—ì„œëŠ” Isì™€ Itì—ì„œ occlusionì´ ì—†ëŠ” ì˜ì—­ë§Œì„ segmentationìœ¼ë¡œ íƒìƒ‰í•´ì„œ swapping í–ˆê¸° ë•Œë¬¸ì— ë¬¸ì œê°€ ìˆì—ˆë‹¤.

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%202.png)

í•™ìŠµëª©í‘œ : Fsì˜ ê²°ê³¼ì¸ ~Irê°€ Ftì˜ St ì–¼êµ´ ì˜ì—­ì„ cover í•˜ë„ë¡í•˜ì—¬  Fsì˜ occlusionì„ Ftì˜ ì–¼êµ´ì— ë§ì¶”ì–´ ì±„ì›Œì¤Œ

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%2022.png)

(ì €ìì˜ ECCV oral ì„¤ëª… ë°œì·Œ)

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%2023.png)

 

### 3.5. Face blending

Fsì™€ FtëŠ” skin toneê³¼ lightingì´ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— í•´ë‹¹ ì°¨ì´ë¥¼ ë§ì¶”ëŠ” ì‘ì—… í•„ìš”

ë…¼ë¬¸ â€˜**Semantic Image Inpainting with Deep Generative Models**â€™ ìœ¼ë¡œë¶€í„° ì•„ì´ë””ì–´ë¥¼ ì–»ì–´ 

**poisson blending optimization**ë¥¼ ì ìš©

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%2024.png)

## 4. Datasets and training

### 4.1. Datasets and processing

**Gr í•™ìŠµ :** 

IJB-C ë°ì´í„°ì…‹ì„ ì‚¬ìš©, 11k ê°œì¤‘ HD í•´ìƒë„ 5.5k ê°œ videoë¥¼ ì‚¬ìš©

3.3ì˜ pruning ê¸°ë²•ì„ ì´ìš©í•´ frame ì œê±°

**Gs í•™ìŠµ** : 

ì‚¬ì§„ì´ ì´ë¯¸ì§€ì—ì„œ ì°¨ì§€í•˜ëŠ” ë¹„ìœ¨ì´ 15% ì´í•˜ì¸ ê²½ìš° ì œê±°

dlib ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•˜ì—¬ ì „ì²´ ì´ë¯¸ì§€ì—ì„œ subject ë³„ 100ê°œì˜ ì´ë¯¸ì§€ë¡œ grouping ìˆ˜í–‰(2D landmark ë³€í™”ê°€ ìµœëŒ€ê°€ ë˜ë„ë¡ ì„ íƒ)

**Perceptual loss :**

VGG-19 í•™ìŠµì‹œ

1) VGGFace2(**3.3M** images depicting **9,131  ID**)ë¡œ FRí•™ìŠµ 

2) CelebA(**202k** images with **40** binary attributes)ë¡œ face attribute classification í•™ìŠµ

## 5. **Experiment Results**

---

### **1) Qualitative face reenactment results**

- ì œì•ˆí•œ ê¸°ë³¸ ë°©ë²•ë¡ ì„ ì´ìš©í•´ ì–»ì€ ê²°ê³¼
- ì¼ë°˜ì ì¸ ì •ì„±ì  ê²°ê³¼  : 4ë²ˆì§¸ ì—´ì˜ ê·¹ë‹¨ì  ì°¨ì´(Poseì™€ Expressionì´ ë§¤ìš° í¼)ì—ë„ ëŒ€ì‘ê°€ëŠ¥
- Yaw í¬ê¸°ì— ë”°ë¥¸ ê²°ê³¼  : í° angle ë³€í™”ì— ëŒ€í•´ iterative ë°©ì‹ìœ¼ë¡œ ì ‘ê·¼í•˜ë©´ IDì™€ textureê°€ ë” ì˜ ë³´ì¡´ (ì˜ê²¬ : í° ì°¨ì´ëŠ” ì—†ì–´ ë³´ì„)

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%2025.png)

### 2) **Qualitative face swapping results**

ì‹¤í—˜ë°ì´í„° : FaceForensics++

ë‹¤ì–‘í•œ í‘œì •, ì–¼êµ´, occlusion ì¼€ì´ìŠ¤ ì‚¬ìš© [35]ì™€ ëŒ€ë“±í•œ ë¹„êµë¥¼ ìœ„í•´ targetê³¼ ê°€ì¥ ìœ ì‚¬í•œ ìì„¸ì˜ source ì„ íƒ( KC ì´í•´ì•ˆë¨)

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%2026.png)

### **3) Comparison to Face2Face**

Face2Faceì™€ ë™ì¼í•˜ê²Œ ì…ë§Œ ì „ì†¡í•˜ëŠ” ë¬¸ì œë¡œ ì •ì˜ Face2FaceëŠ” ì „ë°˜ì ìœ¼ë¡œ artifactê°€ ë‚˜íƒ€ë‚˜ë©° target ì… ëª¨ì–‘ì„ ì˜ í‘œí˜„í•˜ì§€ ëª»í•¨

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%2027.png)

### **4) Quantitative results**

sourceì˜ ID ë³´ì¡´ & targetì˜ ìì„¸/í‘œì • ë°˜ì˜ 1, 2) í’ˆì§ˆÂ  ë¹„êµÂ Â Â  : ID, SSIM(dlib ì–¼êµ´ì¸ì‹/íƒì§€ë“± ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬) (ID : Face Recognition ëª¨ë¸ì„ í†µê³¼í•œ ê°’ì˜ ì°¨ì´ë¡œ ê³„ì‚°í•  ë“¯) (SSIM : ìš°ë¦¬ëˆˆì€ artifactë¥¼ ì˜ ë°œê²¬í•˜ì§€ë§Œ SSIMì€ ì œëŒ€ë¡œ ë°˜ì˜í•˜ì§€ ëª»í•´ì„œ ìˆ˜ì¹˜ì˜ ì°¨ì´ê°€ ë°œê²¬ë˜ì§€ ì•ŠìŒ)

3) ìì„¸ ì •í™•ë„ : Euler angleì˜ ìœ í´ë¦¬ë“œ ê±°ë¦¬ ; ë‹¨ìœ„ degree(Fb vs It) 4) í‘œì • ì •í™•ë„ : 2D landmark ìœ í´ë¦¬ë“œ ê±°ë¦¬; ë‹¨ìœ„ pixel (Fb vs It) (FaceForensics++ì—ì„œ 500ê°œì˜ ë¹„ë””ì˜¤ì˜ ì²« 100ê°œ í”„ë ˆì„ ê´€ì¸¡ê°’ì— ëŒ€í•œ í‰ê· ê³¼ ë¶„ì‚° ì¶”ì¶œ)  IDì™€ SSIMìœ ìœ ì‚¬í•˜ì§€ë§Œ ìì„¸ì™€ í‘œì •ì´ ì˜ ë°˜ì˜

(ê·œì²  : SSIMì´ ì•Œë§ì€ performance measureì¸ê°€?)

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%2028.png)

### **5) Ablation Study**

ì•„ë˜ 4ê°€ì§€ ì¼€ì´ìŠ¤ ë¹„êµ 
(GsëŠ” ê³ ì • ì‚¬ìš©)

ëª¨ë“  ê²½ìš° ID ë™ì¼ 

ìì„¸ì™€ í‘œì •ì—ì„œ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ìŒ

SSIM ì„±ëŠ¥ í•˜ë½ : ì¶”ê°€ ë„¤íŠ¸ì›Œí¬ì™€ ì²˜ë¦¬ë‹¨ê³„ê°€ ì¶”ê°€ê°€ ì›ì¸

![Untitled](FSGAN%20Subject%20Agnostic%20Face%20Swapping%20and%20Reenacmen%2018852680da9144e19a34a7a6c7f1cae3/Untitled%2029.png)

## 6. Conclusion

---

### **Limitations.**

1) iterationì„ ë§ì´ ë¶„í•  í•˜ë©´ texture blurê°€ ì‹¬í•´ì§

2) ì•„ë˜ ê·¸ë¦¼ì—ì„œ ë³´ëŠ” ê²ƒê³¼ ê°™ì´ í¬ì¦ˆì˜ ì°¨ì´ê°€ ì»¤ì§ˆ ìˆ˜ë¡ IDì™€ texture í’ˆì§ˆì´ ì €í•˜ë¨

3) Face2Face ì²˜ëŸ¼ ì´ë¯¸ì§€ë¡œë¶€í„° textureë¥¼ warpí•˜ëŠ” 3DMM ê¸°ë°˜ ë°©ë²•ê³¼ ë‹¬ë¦¬ ë³¸ ë°©ì‹ì€ í•™ìŠµë°ì´í„° í•´ìƒë„ì˜ í•œê³„ì— í’ˆì§ˆì´ ì œí•œë¨

4) Landmarkë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— landmark ê°€ sparseí•œ ê²½ìš° ë³µì¡í•œ í‘œì •ì„ ì˜ ë”°ë¼ê°€ì§€ ëª»í•  ìˆ˜ ìˆìŒ